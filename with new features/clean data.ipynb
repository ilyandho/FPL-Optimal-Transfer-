{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from thefuzz import fuzz, process\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasons with id_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fpl_players(fpl_subfolders, season):\n",
    "    for folder in fpl_subfolders:\n",
    "        player_name = folder.split('/')[4].split('_')\n",
    "        clean_player_name = \" \".join(player_name[0:-1])\n",
    "        player_df = pd.read_csv(str(folder+'/gw.csv'))\n",
    "\n",
    "        player_dir = './data/joint/'+str(season)+'/fpl/'\n",
    "         # Check if player_dir exists\n",
    "        if not os.path.exists(player_dir):\n",
    "            os.makedirs(player_dir)\n",
    "        player_df.to_csv(player_dir + str(clean_player_name) + '.csv', index_label=False)\n",
    "\n",
    "    print('successfully cleaned 20'+ season +' fpl data')\n",
    "\n",
    "# Understat Files\n",
    "def save_under_players(understat_files, season):\n",
    "    for file_ in understat_files:\n",
    "        player_name = file_.split('/')[4].split('_')\n",
    "        clean_player_name = \" \".join(player_name[0:-1])\n",
    "        player_df = pd.read_csv(str(file_))\n",
    "\n",
    "        player_dir = './data/joint/'+str(season)+'/understat/'\n",
    "        # Check if player_dir exists\n",
    "        if not os.path.exists(player_dir):\n",
    "            os.makedirs(player_dir)\n",
    "        player_df.to_csv(player_dir + str(clean_player_name) + '.csv', index_label=False)\n",
    "\n",
    "    print('successfully cleaned understat 20'+ season +' data')\n",
    "\n",
    "def joint_players_info(fpl_player_folder_path, understat_player_folder_path, season):\n",
    "    fpl_subfolders = [ f.path for f in os.scandir(fpl_player_folder_path) if f.is_dir() ]\n",
    "    under_files = [ f.path for f in os.scandir(understat_player_folder_path) if f.is_file() ]\n",
    "\n",
    "    save_fpl_players(fpl_subfolders, season)\n",
    "    save_under_players(under_files, season)\n",
    "\n",
    "    print('20'+ season +' fpl and understat data now in `joint` folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_fpl_understat_data(fpl_player_folder_path, understat_player_folder_path, season):\n",
    "    joint_players_info(fpl_player_folder_path, understat_player_folder_path, season)\n",
    "\n",
    "    joint_fpl_data_path = \"./data/joint/\"+ season + \"/fpl/\"\n",
    "    joint_understat_path = \"./data/joint/\"+ season + \"/understat/\"\n",
    "\n",
    "    understat_files= next(os.walk(\"./data/joint/\"+ season + \"/understat/\"), (None, None, []))[2]  # [] if no file\n",
    "    fpl_files = next(os.walk( \"./data/joint/\"+ season +\"/fpl\"), (None, None, []))[2]  # [] if no file\n",
    "    player_ids = pd.read_csv('./data/20'+ season +'/id_dict.csv')\n",
    "\n",
    "    understat_names = [file_.split('.')[0] for file_ in understat_files]\n",
    "    fpl_names = [file_.split('.')[0] for file_ in fpl_files]\n",
    "\n",
    "    for name in understat_names:\n",
    "        # print(name)\n",
    "        player_index = player_ids.index[player_ids['Understat_Name'] == name].tolist()\n",
    "\n",
    "        if(player_index):\n",
    "            indexed_fpl_name = player_ids.loc[player_index[0], 'FPL_Name']\n",
    "\n",
    "            if(indexed_fpl_name):\n",
    "                # Use Fuzzy matching get the corresponding fpl name\n",
    "                fuzzy_fpl_player_name = process.extractOne(indexed_fpl_name, fpl_names, scorer=fuzz.partial_token_sort_ratio)\n",
    "\n",
    "                fpl_player_data = pd.read_csv(joint_fpl_data_path + str(fuzzy_fpl_player_name[0])+ '.csv')\n",
    "                understat_player_data = pd.read_csv(joint_understat_path + name + '.csv')\n",
    "\n",
    "                # Change 'kickoff_time' column name to 'date\n",
    "                fpl_player_data = fpl_player_data.rename(columns={'kickoff_time': 'date'})\n",
    "                # change the formats: From 2021-10-03T13:00:00Z to 2021-10-03\n",
    "                fpl_player_data.date = fpl_player_data.date.apply(lambda x: x.split('T')[0])\n",
    "\n",
    "                # Dates are of the form 2021-10-03T13:00:00Z\n",
    "                fpl_dates_min = fpl_player_data['date'].min()\n",
    "                fpl_dates_max = fpl_player_data['date'].max()\n",
    "\n",
    "                # Filter out player info not in the range of dates we are dealing with\n",
    "                understat_filtered = understat_player_data[(pd.to_datetime(understat_player_data['date']) > pd.to_datetime(fpl_dates_min))\n",
    "                                                            & (pd.to_datetime(understat_player_data['date']) < pd.to_datetime(fpl_dates_max) )]\n",
    "\n",
    "                # Marge fpl_player_data with understat_player_data if the dates match\n",
    "                player_data_merged = fpl_player_data.merge(understat_filtered, on=\"date\")\n",
    "                if(player_data_merged.shape[0]):\n",
    "                    merged_dir = './data/joint/'+ season +'/merged/'\n",
    "                    if not os.path.exists(merged_dir):\n",
    "                        os.makedirs(merged_dir)\n",
    "\n",
    "                    player_data_merged.to_csv(merged_dir+ indexed_fpl_name +'.csv', index_label=False )\n",
    "\n",
    "\n",
    "    print('sucessfully merged 20 '+ season +' data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_difficulty(season):\n",
    "    print('====> Starting to add difficulty features to 20'+season)\n",
    "    merged = './data/joint/' + season + '/merged/'\n",
    "    player_names = next(os.walk((merged), (None, None, [])))[2]\n",
    "    fixtures = pd.read_csv('./data/20' + season + '/fixtures.csv')\n",
    "\n",
    "    # for name in player_names:\n",
    "    #     player  = pd.read_csv('./data/joint/' + season + '/merged/'+ name)\n",
    "    #     new_col = {'team_h_difficulty':[], 'team_a_difficulty':[]}\n",
    "\n",
    "    #     for index, row in player.iterrows():\n",
    "    #         for idx, row_2 in fixtures.iterrows():\n",
    "    #             if row['fixture'] == row_2['id']:\n",
    "    #                 new_col['team_h_difficulty'].append(row_2['team_h_difficulty'])\n",
    "    #                 new_col['team_a_difficulty'].append(row_2['team_a_difficulty'])\n",
    "\n",
    "    #     with_new_cols = [player, pd.DataFrame(new_col)]\n",
    "    #     player_with_difficult = pd.concat(with_new_cols, axis=1)\n",
    "    #     new_col_dir = './data/joint/' + season +'/merged_extras/'\n",
    "    #     if not os.path.exists(new_col_dir):\n",
    "    #         os.makedirs(new_col_dir)\n",
    "    #     player_with_difficult.to_csv(new_col_dir + name)\n",
    "\n",
    "    # Loop over each player file in player_names\n",
    "    for name in player_names:\n",
    "        # Load player data\n",
    "        player = pd.read_csv('./data/joint/' + season + '/merged/' + name)\n",
    "\n",
    "        # Function to get the difficulty and was_home columns based on the fixture\n",
    "        def get_fixture_info(row):\n",
    "            # Filter the relevant fixture\n",
    "            fixture = fixtures[fixtures['id'] == row['fixture']]\n",
    "            if not fixture.empty:\n",
    "                fixture = fixture.iloc[0]  # Get the first (and only) match\n",
    "\n",
    "                # Get the team difficulties\n",
    "                team_h_difficulty = fixture['team_h_difficulty']\n",
    "                team_a_difficulty = fixture['team_a_difficulty']\n",
    "                event = fixture['event']\n",
    "\n",
    "                return pd.Series([team_h_difficulty, team_a_difficulty, event])\n",
    "            else:\n",
    "                # Return NaN if no matching fixture found\n",
    "                return pd.Series([None, None, None])\n",
    "\n",
    "        # Apply the function to each row of player\n",
    "        player[['team_h_difficulty', 'team_a_difficulty', 'event']] = player.apply(get_fixture_info, axis=1)\n",
    "\n",
    "        # Save the updated DataFrame with the new columns\n",
    "        new_col_dir = './data/joint/' + season + '/merged_extras/'\n",
    "        if not os.path.exists(new_col_dir):\n",
    "            os.makedirs(new_col_dir)\n",
    "        player.to_csv(new_col_dir + name, index=False)\n",
    "\n",
    "    print('****> successfully added difficulty features to 20'+season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully cleaned 2021-22 fpl data\n",
      "successfully cleaned understat 2021-22 data\n",
      "2021-22 fpl and understat data now in `joint` folder\n",
      "sucessfully merged 20 21-22 data\n",
      "successfully cleaned 2022-23 fpl data\n",
      "successfully cleaned understat 2022-23 data\n",
      "2022-23 fpl and understat data now in `joint` folder\n",
      "sucessfully merged 20 22-23 data\n",
      "successfully cleaned 2023-24 fpl data\n",
      "successfully cleaned understat 2023-24 data\n",
      "2023-24 fpl and understat data now in `joint` folder\n",
      "sucessfully merged 20 23-24 data\n",
      "successfully cleaned 2024-25 fpl data\n",
      "successfully cleaned understat 2024-25 data\n",
      "2024-25 fpl and understat data now in `joint` folder\n",
      "sucessfully merged 20 24-25 data\n"
     ]
    }
   ],
   "source": [
    "merge_fpl_understat_data(\"./data/2021-22/players/\", \"./data/2021-22/understat/\", \"21-22\")\n",
    "merge_fpl_understat_data(\"./data/2022-23/players/\", \"./data/2022-23/understat/\", \"22-23\")\n",
    "merge_fpl_understat_data(\"./data/2023-24/players/\", \"./data/2023-24/understat/\", \"23-24\")\n",
    "merge_fpl_understat_data(\"./data/2024-25/players/\", \"./data/2024-25/understat/\", \"24-25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding fixture difficulty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Starting to add difficulty features to 2021-22\n",
      "****> successfully added difficulty features to 2021-22\n",
      "====> Starting to add difficulty features to 2022-23\n",
      "****> successfully added difficulty features to 2022-23\n",
      "====> Starting to add difficulty features to 2023-24\n",
      "****> successfully added difficulty features to 2023-24\n",
      "====> Starting to add difficulty features to 2024-25\n",
      "****> successfully added difficulty features to 2024-25\n"
     ]
    }
   ],
   "source": [
    "add_difficulty('21-22')\n",
    "add_difficulty('22-23')\n",
    "add_difficulty('23-24')\n",
    "add_difficulty('24-25')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Expected points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_xP(season):\n",
    "    print('================> starting season 20'+season)\n",
    "    players_paths = next(os.walk('./data/joint/'+ season +'/merged_extras', [None], [None],[]))[2]\n",
    "    # players_paths\n",
    "    for path in players_paths:\n",
    "        player = pd.read_csv('./data/joint/'+ season +'/merged_extras/'+ path)\n",
    "        merged = pd.read_csv('./data/20'+ season +'/gws/merged_gw.csv')\n",
    "\n",
    "        player = player.drop(['position'], axis=1)\n",
    "        merged_player = pd.merge(player, merged[['element', 'fixture', 'xP','position']], on=['element', 'fixture'], how='left')\n",
    "\n",
    "        # Save the updated DataFrame with the new columns\n",
    "        new_col_dir = './data/joint/'+ season +'/merged_extras_xP/'\n",
    "        if not os.path.exists(new_col_dir):\n",
    "            os.makedirs(new_col_dir)\n",
    "        merged_player.to_csv(new_col_dir + path, index=False)\n",
    "\n",
    "    print('<<<<================ starting season 20'+season)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================> starting season 2021-22\n",
      "<<<<================ starting season 2021-22\n",
      "================> starting season 2022-23\n",
      "<<<<================ starting season 2022-23\n",
      "================> starting season 2023-24\n",
      "<<<<================ starting season 2023-24\n",
      "================> starting season 2024-25\n",
      "<<<<================ starting season 2024-25\n"
     ]
    }
   ],
   "source": [
    "add_xP('21-22')\n",
    "add_xP('22-23')\n",
    "add_xP('23-24')\n",
    "add_xP('24-25')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add rolling averages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rolling_avgs(season):\n",
    "    print('================> starting season 20'+season)\n",
    "    players_paths = next(os.walk('./data/joint/'+ season +'/merged_extras_xP', [None], [None],[]))[2]\n",
    "    for path in players_paths:\n",
    "        player = pd.read_csv('./data/joint/'+ season +'/merged_extras_xP/'+ path,sep=',', skipinitialspace=True)\n",
    "\n",
    "        prev = [[0 for i in range(32)],[0 for i in range(32)],[0 for i in range(32)]]\n",
    "        gwks = [1]\n",
    "\n",
    "        def rolling(row):\n",
    "            row_items = [\n",
    "                row['clean_sheets'], row['creativity'], row['expected_assists'], row['expected_goal_involvements'], row['expected_goals'], row['expected_goals_conceded'],\n",
    "                row['goals_conceded'], row['goals_scored'], row['influence'], row['minutes'], row['own_goals'], row['penalties_missed'], row['penalties_saved'], row['red_cards'],\n",
    "                 row['saves'], row['starts'],  row['team_a_score'],  row['team_h_score'], row['total_points'], row['yellow_cards'], row['goals'], row['shots'], row['xG'], row['xA'],\n",
    "                 row['assists_y'], row['key_passes'], row['npg'], row['npxG'], row['xGChain'],  row['xGBuildup'], row['xP']\n",
    "                ]\n",
    "\n",
    "            if row['event'] - gwks[0] == 0:\n",
    "                del prev[2]\n",
    "                prev.append(row_items)\n",
    "\n",
    "            elif row['event'] - gwks[0] == 1:\n",
    "                del prev[0]\n",
    "                prev.append(row_items)\n",
    "                gwks[0] = row['event']\n",
    "\n",
    "            elif row['event'] - gwks[0] == 2:\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                prev.append([0 for i in range(32)])\n",
    "                prev.append(row_items)\n",
    "                gwks[0] = row['event']\n",
    "\n",
    "            else:\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                prev.append([0 for i in range(32)])\n",
    "                prev.append([0 for i in range(32)])\n",
    "                prev.append(row_items)\n",
    "                gwks[0] = row['event']\n",
    "\n",
    "            return pd.Series([round((x+y+z)/3 ,2) for x,y,z in zip(prev[0], prev[1], prev[2])])\n",
    "\n",
    "        player[\n",
    "                [\n",
    "                    'clean_sheets_3', 'creativity_3', 'expected_assists_3', 'expected_goal_involvements_3', 'expected_goals_3', 'expected_goals_conceded_3',\n",
    "                    'goals_conceded_3', 'goals_scored_3', 'influence_3', 'minutes_3', 'own_goals_3', 'penalties_missed_3', 'penalties_saved_3',\n",
    "                    'red_cards_3', 'saves_3', 'starts_3',  'team_a_score_3',  'team_h_score_3', 'total_points_3', 'yellow_cards_3', 'goals_3', 'shots_3', 'xG_3',\n",
    "                    'xA_3', 'assists_y_3', 'key_passes_3', 'npg_3', 'npxG_3', 'xGChain_3',  'xGBuildup_3',  'xP_3'\n",
    "                ]\n",
    "            ] = player.apply(rolling, axis=1)\n",
    "        # # Drop the rolled columns\n",
    "        # player.drop([\n",
    "        #             'clean_sheets', 'creativity', 'expected_assists', 'expected_goal_involvements', 'expected_goals', 'expected_goals_conceded',\n",
    "        #             'goals_conceded', 'goals_scored', 'influence', 'minutes', 'own_goals', 'penalties_missed', 'penalties_saved',\n",
    "        #             'red_cards', 'saves', 'starts',  'team_a_score',  'team_h_score', 'total_points', 'yellow_cards', 'goals', 'shots', 'xG',\n",
    "        #             'xA', 'assists_y', 'key_passes', 'npg', 'npxG', 'xGChain',  'xGBuildup',  'xP'\n",
    "        #         ], axis=1  )\n",
    "        # Save the updated DataFrame with the new columns\n",
    "        new_col_dir = './data/joint/'+ season +'/merged_extras_rolled/'\n",
    "        if not os.path.exists(new_col_dir):\n",
    "            os.makedirs(new_col_dir)\n",
    "        player.to_csv(new_col_dir + path, index=False)\n",
    "\n",
    "    print('<<<<================ starting season 20'+season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================> starting season 2022-23\n",
      "<<<<================ starting season 2022-23\n",
      "================> starting season 2023-24\n",
      "<<<<================ starting season 2023-24\n",
      "================> starting season 2024-25\n",
      "<<<<================ starting season 2024-25\n"
     ]
    }
   ],
   "source": [
    "add_rolling_avgs('22-23')\n",
    "add_rolling_avgs('23-24')\n",
    "add_rolling_avgs('24-25')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add odds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h_team</th>\n",
       "      <th>a_team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brighton</td>\n",
       "      <td>Manchester United</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manchester United</td>\n",
       "      <td>Liverpool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Southampton</td>\n",
       "      <td>Manchester United</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>Manchester United</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Manchester United</td>\n",
       "      <td>Tottenham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              h_team             a_team\n",
       "0           Brighton  Manchester United\n",
       "1  Manchester United          Liverpool\n",
       "2        Southampton  Manchester United\n",
       "3     Crystal Palace  Manchester United\n",
       "4  Manchester United          Tottenham"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolled = pd.read_csv('./data/joint/24-25/merged_extras_rolled/Bruno Borges Fernandes.csv')\n",
    "(rolled[['h_team' ,'a_team']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WHH</th>\n",
       "      <th>HomeTeam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [WHH, HomeTeam]\n",
       "Index: []"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f  = pd.read_csv('./data/odds/E0 24-25.csv')\n",
    "f[f['HomeTeam'] == 'Manchester United'][['WHH', 'HomeTeam']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h_team</th>\n",
       "      <th>a_team</th>\n",
       "      <th>WHH</th>\n",
       "      <th>WHD</th>\n",
       "      <th>WHA</th>\n",
       "      <th>date</th>\n",
       "      <th>total_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brighton</td>\n",
       "      <td>Manchester United</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-08-24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manchester United</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Southampton</td>\n",
       "      <td>Manchester United</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-09-14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>Manchester United</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-09-21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Manchester United</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-09-29</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              h_team             a_team   WHH   WHD   WHA        date  \\\n",
       "0           Brighton  Manchester United  None  None  None  2024-08-24   \n",
       "1  Manchester United          Liverpool  None  None  None  2024-09-01   \n",
       "2        Southampton  Manchester United  None  None  None  2024-09-14   \n",
       "3     Crystal Palace  Manchester United  None  None  None  2024-09-21   \n",
       "4  Manchester United          Tottenham  None  None  None  2024-09-29   \n",
       "\n",
       "   total_points  \n",
       "0             2  \n",
       "1             2  \n",
       "2             5  \n",
       "3             3  \n",
       "4            -2  "
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the odds data once to avoid redundant file reads\n",
    "odds = pd.read_csv('./data/odds/E0 24-25.csv')\n",
    "odds = odds.rename(columns={'HomeTeam': 'h_team', 'AwayTeam': 'a_team'})\n",
    "\n",
    "def add_odds(row, odds):\n",
    "    # Filter the odds DataFrame for the matching teams\n",
    "    match = odds[(odds['h_team'] == row['h_team']) & (odds['a_team'] == row['a_team'])]\n",
    "\n",
    "    # Check if a match is found\n",
    "    if not match.empty:\n",
    "        # Extract the relevant odds values\n",
    "        odds_ = match.iloc[0]\n",
    "        WHH = odds_['WHH']\n",
    "        WHD = odds_['WHD']\n",
    "        WHA = odds_['WHA']\n",
    "        return pd.Series([WHH, WHD, WHA])\n",
    "    else:\n",
    "        # Return NaN for rows with no match\n",
    "        return pd.Series([None, None, None])\n",
    "\n",
    "# Apply the function to the 'rolled' DataFrame\n",
    "rolled[['WHH', 'WHD', 'WHA']] = rolled.apply(add_odds, axis=1, odds=odds)\n",
    "\n",
    "rolled[['h_team','a_team', 'WHH','WHD', 'WHA', 'date', 'total_points']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['bonus', 'clean_sheets','expected_assists (xA)', 'expected_goal_involvements', 'expected_goals (xG)', 'expected_goals_conceded', 'ict_index', 'minutes',\n",
    "            'red_cards','total_points', 'was_home', 'yellow_cards', 'shots', 'npxG', 'xGChain', 'xGBuildup', 'team_h_difficulty', 'team_a_difficulty', 'opponent_team',\n",
    "             'threat', 'value', 'key_passes',\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "    Total Points â€“ Bonus Points (tp-bp), Minutes, Yellow Cards, Red Cards, Expected Goals (xG), Expected Assists (xA), Non-penalty Expected Goals (npxG),\n",
    "    Shots, Expected Goals Against, Expected_goal_involvements,  clean_sheets, ict_index, opponent_team, Expected Goals Buildup (xG Buildup), threat, value,\n",
    "    Key Passes,\n",
    "\n",
    "\n",
    "    Games,  Expected Goals Chain (xG Chain),  Non-penalty Expected Goal Difference (npxGD), Non-penalty Expected Goals Against (npxGA), Expected Points (xPts)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### Merge data -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_files(season):\n",
    "    paths = next(os.walk('./data/joint/'+ season +'/merged_extras_xP', [None], [None],[]))[2]\n",
    "    files_list = [pd.read_csv('./data/joint/'+ season +'/merged_extras_xP/' + path)  for  path in paths ]\n",
    "    merged_files = pd.concat(files_list)\n",
    "\n",
    "    # Save the new DataFrame\n",
    "    new_col_dir = './data/joint/'+ season +'/'\n",
    "    print(new_col_dir)\n",
    "\n",
    "    merged_files.to_csv(new_col_dir  +'merged_player_data.csv', index=False)\n",
    "    # print('<<<<================ starting season 20'+ season)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/joint/21-22/\n",
      "./data/joint/22-23/\n",
      "./data/joint/23-24/\n",
      "./data/joint/24-25/\n"
     ]
    }
   ],
   "source": [
    "merge_files('21-22')\n",
    "merge_files('22-23')\n",
    "merge_files('23-24')\n",
    "merge_files('24-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2\n",
       "1       5\n",
       "2       3\n",
       "3       4\n",
       "4       5\n",
       "       ..\n",
       "1040    5\n",
       "1041    6\n",
       "1042    2\n",
       "1043    3\n",
       "1044    5\n",
       "Name: round, Length: 1045, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./data/joint/24-25/merged_player_data.csv')[ 'round']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FPL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
