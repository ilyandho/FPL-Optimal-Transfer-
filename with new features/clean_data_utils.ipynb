{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from thefuzz import fuzz, process\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Util functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fpl_players(fpl_subfolders, season):\n",
    "\n",
    "    for folder in fpl_subfolders:\n",
    "        # print(folder)\n",
    "        # print('flp: ', folder)\n",
    "        player_name = folder.split('/')[6].split('_')\n",
    "        clean_player_name = \" \".join(player_name[0:-1])\n",
    "        player_df = pd.read_csv(str(folder+'/gw.csv'))\n",
    "        player_dir = './data/joint/'+str(season)+'/fpl/'\n",
    "         # Check if player_dir exists\n",
    "\n",
    "\n",
    "        if not os.path.exists(player_dir):\n",
    "            os.makedirs(player_dir)\n",
    "        player_df.to_csv(player_dir + str(clean_player_name) + '.csv', index_label=False)\n",
    "\n",
    "    print('successfully cleaned 20'+ season +' fpl data')\n",
    "\n",
    "# Understat Files\n",
    "def save_under_players(understat_files, season):\n",
    "    for file_ in understat_files:\n",
    "        player_name = file_.split('/')[6].split('_')\n",
    "        clean_player_name = \" \".join(player_name[0:-1])\n",
    "        player_df = pd.read_csv(str(file_))\n",
    "\n",
    "        player_dir = './data/joint/'+str(season)+'/understat/'\n",
    "        # Check if player_dir exists\n",
    "        if not os.path.exists(player_dir):\n",
    "            os.makedirs(player_dir)\n",
    "        player_df.to_csv(player_dir + str(clean_player_name) + '.csv', index_label=False)\n",
    "\n",
    "    print('successfully cleaned understat 20'+ season +' data')\n",
    "\n",
    "def joint_players_info(fpl_player_folder_path, understat_player_folder_path, season):\n",
    "    fpl_subfolders = [ f.path for f in os.scandir(fpl_player_folder_path) if f.is_dir() ]\n",
    "    under_files = [ f.path for f in os.scandir(understat_player_folder_path) if f.is_file() ]\n",
    "\n",
    "    save_fpl_players(fpl_subfolders, season)\n",
    "    save_under_players(under_files, season)\n",
    "\n",
    "    print('20'+ season +' fpl and understat data now in `joint` folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_fpl_understat_data(fpl_player_folder_path, understat_player_folder_path, season):\n",
    "    joint_players_info(fpl_player_folder_path, understat_player_folder_path, season)\n",
    "\n",
    "    joint_fpl_data_path = \"./data/joint/\"+ season + \"/fpl/\"\n",
    "    joint_understat_path = \"./data/joint/\"+ season + \"/understat/\"\n",
    "\n",
    "    understat_files= next(os.walk(\"./data/joint/\"+ season + \"/understat/\"), (None, None, []))[2]  # [] if no file\n",
    "    fpl_files = next(os.walk( \"./data/joint/\"+ season +\"/fpl\"), (None, None, []))[2]  # [] if no file\n",
    "    player_ids = pd.read_csv('./data/20'+ season +'/id_dict.csv')\n",
    "\n",
    "    understat_names = [file_.split('.')[0] for file_ in understat_files]\n",
    "    fpl_names = [file_.split('.')[0] for file_ in fpl_files]\n",
    "\n",
    "    # print('[[[[[[[[[[[]]]]]]]]]]]', understat_names)\n",
    "    for name in understat_names:\n",
    "        # print(name)\n",
    "        player_index = player_ids.index[player_ids['Understat_Name'] == name].tolist()\n",
    "\n",
    "        if(player_index):\n",
    "            indexed_fpl_name = player_ids.loc[player_index[0], 'FPL_Name']\n",
    "            if(indexed_fpl_name):\n",
    "                # Use Fuzzy matching get the corresponding fpl name\n",
    "                fuzzy_fpl_player_name = process.extractOne(indexed_fpl_name, fpl_names, scorer=fuzz.partial_token_sort_ratio)\n",
    "\n",
    "                fpl_player_data = pd.read_csv(joint_fpl_data_path + str(fuzzy_fpl_player_name[0])+ '.csv')\n",
    "                understat_player_data = pd.read_csv(joint_understat_path + name + '.csv')\n",
    "                # Change 'kickoff_time' column name to 'date\n",
    "                fpl_player_data = fpl_player_data.rename(columns={'kickoff_time': 'date'})\n",
    "                # change the formats: From 2021-10-03T13:00:00Z to 2021-10-03\n",
    "                fpl_player_data.date = fpl_player_data.date.apply(lambda x: x.split('T')[0])\n",
    "\n",
    "                # Dates are of the form 2021-10-03T13:00:00Z\n",
    "                fpl_dates_min = fpl_player_data['date'].min()\n",
    "                fpl_dates_max = fpl_player_data['date'].max()\n",
    "\n",
    "\n",
    "                # Filter out player info not in the range of dates we are dealing with\n",
    "                understat_filtered = understat_player_data[(pd.to_datetime(understat_player_data['date']) >= pd.to_datetime(fpl_dates_min))\n",
    "                                                            & (pd.to_datetime(understat_player_data['date']) <= pd.to_datetime(fpl_dates_max) )]\n",
    "\n",
    "                # Marge fpl_player_data with understat_player_data if the dates match\n",
    "                player_data_merged = fpl_player_data.merge(understat_filtered, on=\"date\")\n",
    "                # print(player_data_merged[player_data_merged['round']==10])\n",
    "\n",
    "\n",
    "                if(player_data_merged.shape[0]):\n",
    "                    merged_dir = './data/joint/'+ season +'/merged/'\n",
    "                    if not os.path.exists(merged_dir):\n",
    "                        os.makedirs(merged_dir)\n",
    "\n",
    "                    player_data_merged.to_csv(merged_dir+ indexed_fpl_name +'.csv', index_label=False )\n",
    "\n",
    "\n",
    "    print('sucessfully merged 20 '+ season +' data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_difficulty(season):\n",
    "    print('====> Starting to add difficulty features to 20'+season)\n",
    "    merged = './data/joint/' + season + '/merged/'\n",
    "\n",
    "    player_names = next(os.walk((merged), (None, None, [])))[2]\n",
    "    fixtures = pd.read_csv('./data/20' + season + '/fixtures.csv')\n",
    "\n",
    "    # Loop over each player file in player_names\n",
    "    for name in player_names:\n",
    "        # Load player data\n",
    "        player = pd.read_csv('./data/joint/' + season + '/merged/' + name)\n",
    "\n",
    "        # Function to get the difficulty and was_home columns based on the fixture\n",
    "        def get_fixture_info(row):\n",
    "            # Filter the relevant fixture\n",
    "            fixture = fixtures[fixtures['id'] == row['fixture']]\n",
    "            if not fixture.empty:\n",
    "                fixture = fixture.iloc[0]  # Get the first (and only) match\n",
    "\n",
    "                # Get the team difficulties\n",
    "                team_h_difficulty = fixture['team_h_difficulty']\n",
    "                team_a_difficulty = fixture['team_a_difficulty']\n",
    "                event = fixture['event']\n",
    "\n",
    "                return pd.Series([team_h_difficulty, team_a_difficulty, event])\n",
    "            else:\n",
    "                # Return NaN if no matching fixture found\n",
    "                return pd.Series([None, None, None])\n",
    "\n",
    "        # Apply the function to each row of player\n",
    "        player[['team_h_difficulty', 'team_a_difficulty', 'event']] = player.apply(get_fixture_info, axis=1)\n",
    "\n",
    "        # Save the updated DataFrame with the new columns\n",
    "        new_col_dir = './data/joint/' + season + '/merged_extras/'\n",
    "        if not os.path.exists(new_col_dir):\n",
    "            os.makedirs(new_col_dir)\n",
    "        player.to_csv(new_col_dir + name, index=False)\n",
    "\n",
    "    # print(player[player['round']== 10])\n",
    "    print('****> successfully added difficulty features to 20'+season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_xP(season):\n",
    "    print('================> starting season 20'+season)\n",
    "    players_paths = next(os.walk('./data/joint/'+ season +'/merged_extras', [None], [None],[]))[2]\n",
    "    # players_paths\n",
    "    for path in players_paths:\n",
    "        player = pd.read_csv('./data/joint/'+ season +'/merged_extras/'+ path)\n",
    "        merged = pd.read_csv('./data/20'+ season +'/gws/merged_gw.csv')\n",
    "\n",
    "        player = player.drop(['position'], axis=1)\n",
    "        merged_player = pd.merge(player, merged[['element', 'fixture', 'xP','position']], on=['element', 'fixture'], how='left')\n",
    "\n",
    "        # Save the updated DataFrame with the new columns\n",
    "        new_col_dir = './data/joint/'+ season +'/merged_extras_xP/'\n",
    "        if not os.path.exists(new_col_dir):\n",
    "            os.makedirs(new_col_dir)\n",
    "        merged_player.to_csv(new_col_dir + path, index=False)\n",
    "\n",
    "    print('<<<<================ starting season 20'+season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rolling_avgs_3(season):\n",
    "    print('================> starting season 20'+season)\n",
    "    players_paths = next(os.walk('./data/joint/'+ season +'/merged_extras_xP', [None], [None],[]))[2]\n",
    "    for path in players_paths:\n",
    "        player = pd.read_csv('./data/joint/'+ season +'/merged_extras_xP/'+ path,sep=',', skipinitialspace=True)\n",
    "\n",
    "        prev = [\n",
    "                [0 for i in range(34)],\n",
    "                [0 for i in range(34)],\n",
    "                [0 for i in range(34)],\n",
    "                [0 for i in range(34)]\n",
    "            ]\n",
    "        gwks = [1]\n",
    "\n",
    "        features = ['clean_sheets', 'expected_assists', 'expected_goal_involvements', 'expected_goals', 'expected_goals_conceded', 'goals_conceded', 'goals_scored', 'ict_index',\n",
    "                    'influence', 'creativity', 'threat', 'minutes', 'own_goals', 'penalties_missed', 'penalties_saved', 'red_cards', 'yellow_cards', 'saves', 'starts',\n",
    "                    'team_a_score', 'team_h_score', 'total_points', 'goals', 'shots', 'xG', 'xA', 'assists_y', 'key_passes', 'npg', 'npxG', 'xGChain',  'xGBuildup',  'xP', 'selected'\n",
    "                    ]\n",
    "\n",
    "        def rolling(row):\n",
    "            row_items = [row.get(col, 0) for col in features]\n",
    "\n",
    "            if row['event'] - gwks[0] == 0:\n",
    "                del prev[3]\n",
    "                prev.append(row_items)\n",
    "\n",
    "            elif row['event'] - gwks[0] == 1:\n",
    "                del prev[0]\n",
    "                prev.append(row_items)\n",
    "                gwks[0] = row['event']\n",
    "\n",
    "            elif row['event'] - gwks[0] == 2:\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append(row_items)\n",
    "                gwks[0] = row['event']\n",
    "\n",
    "            else:\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append(row_items)\n",
    "                gwks[0] = row['event']\n",
    "\n",
    "            # print(row['event'], len(pd.Series([round((x+y+z)/3 ,2) for x,y,z in zip(prev[0], prev[1], prev[2])])),  prev[0], prev[1], prev[2], prev[3]) #\n",
    "            return pd.Series([round((x+y+z) ,2) for x,y,z in zip(prev[0], prev[1], prev[2])])\n",
    "        player[[f\"{col}_3\" for col in features]] = player.apply(rolling, axis=1)\n",
    "\n",
    "        # Save the updated DataFrame with the new columns\n",
    "        new_col_dir = f'./data/joint/{season}/merged_extras_rolled_3/'\n",
    "        if not os.path.exists(new_col_dir):\n",
    "            os.makedirs(new_col_dir)\n",
    "        player.to_csv(new_col_dir + path, index=False)\n",
    "\n",
    "    print('<<<<================ starting season 20'+season)\n",
    "\n",
    "def add_rolling_avgs_5(season):\n",
    "    print('================> starting season 20'+season)\n",
    "    players_paths = next(os.walk('./data/joint/'+ season +'/merged_extras_rolled_3', [None], [None],[]))[2]\n",
    "    for path in players_paths:\n",
    "        player = pd.read_csv('./data/joint/'+ season +'/merged_extras_rolled_3/'+ path,sep=',', skipinitialspace=True)\n",
    "\n",
    "        prev = [\n",
    "                [0 for i in range(34)],\n",
    "                [0 for i in range(34)],\n",
    "                [0 for i in range(34)],\n",
    "                [0 for i in range(34)],\n",
    "                [0 for i in range(34)],\n",
    "                [0 for i in range(34)]\n",
    "            ]\n",
    "        gwks = [1]\n",
    "\n",
    "        features = ['clean_sheets', 'expected_assists', 'expected_goal_involvements', 'expected_goals', 'expected_goals_conceded', 'goals_conceded', 'goals_scored', 'ict_index',\n",
    "                    'influence', 'creativity', 'threat', 'minutes', 'own_goals', 'penalties_missed', 'penalties_saved', 'red_cards', 'yellow_cards', 'saves', 'starts',\n",
    "                    'team_a_score', 'team_h_score', 'total_points', 'goals', 'shots', 'xG', 'xA', 'assists_y', 'key_passes', 'npg', 'npxG', 'xGChain',  'xGBuildup',  'xP', 'selected'\n",
    "                    ]\n",
    "\n",
    "        def rolling(row):\n",
    "            row_items = [row.get(col, 0) for col in features]\n",
    "\n",
    "            if row['event'] - gwks[0]== 0:\n",
    "                del prev[5]\n",
    "                prev.append(row_items)\n",
    "\n",
    "            elif row['event'] - gwks[0] == 1:\n",
    "                del prev[0]\n",
    "                prev.append(row_items)\n",
    "                gwks[0] = row['event']\n",
    "\n",
    "            elif row['event'] - gwks[0] == 2:\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append(row_items)\n",
    "                gwks[0] = row['event']\n",
    "\n",
    "            elif row['event'] - gwks[0] == 3:\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append(row_items)\n",
    "                gwks[0] = row['event']\n",
    "\n",
    "            elif row['event'] - gwks[0] == 4:\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append(row_items)\n",
    "                gwks[0] = row['event']\n",
    "            else:\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append(row_items)\n",
    "                gwks[0] = row['event']\n",
    "\n",
    "            return pd.Series([round((v+w+x+y+z) ,2) for v, w, x,y,z in zip(prev[0], prev[1], prev[2], prev[3], prev[4])])\n",
    "        player[[f\"{col}_5\" for col in features]] = player.apply(rolling, axis=1)\n",
    "\n",
    "        # Save the updated DataFrame with the new columns\n",
    "        new_col_dir = f'./data/joint/{season}/merged_extras_rolled_5/'\n",
    "        if not os.path.exists(new_col_dir):\n",
    "            os.makedirs(new_col_dir)\n",
    "        player.to_csv(new_col_dir + path, index=False)\n",
    "\n",
    "def add_rolling_avgs(season):\n",
    "    add_rolling_avgs_3(season)\n",
    "    add_rolling_avgs_5(season)\n",
    "\n",
    "    print('<<<<================ Done rolling season 20'+season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odds(sns, nxt_gw=0):\n",
    "    print('================> starting sns 20'+sns)\n",
    "\n",
    "    # print(nxt_gw)\n",
    "    # Load the data data once to avoid redundant file reads\n",
    "    data = pd.read_csv('./data/odds/E0 '+ sns +'.csv')\n",
    "    data = data.rename(columns={'HomeTeam': 'h_team', 'AwayTeam': 'a_team'})\n",
    "\n",
    "    players_paths = next(os.walk('./data/joint/'+ sns +'/merged_extras_rolled_5', [None], [None],[]))[2]\n",
    "    for path in players_paths:\n",
    "        rolled = pd.read_csv('./data/joint/'+ sns +'/merged_extras_rolled_5/'+ path,sep=',', skipinitialspace=True)\n",
    "\n",
    "        def add_odds(row, data):\n",
    "            # Filter the data DataFrame for the matching teams\n",
    "            match = data[(data['h_team'] == row['h_team']) & (data['a_team'] == row['a_team'])]\n",
    "            # Check if a match is found\n",
    "\n",
    "            if not match.empty:\n",
    "                # Extract the relevant data values\n",
    "                # Convert the data to probabilities\n",
    "                odds_ = match.iloc[0]\n",
    "                WHH = round(1/odds_['WHH'], 2)\n",
    "                WHD = round(1/odds_['WHD'], 2)\n",
    "                WHA = round(1/odds_['WHA'], 2)\n",
    "                pts_bps = row['total_points'] - row['bonus']\n",
    "                return pd.Series([pts_bps, WHH, WHD, WHA])\n",
    "            else:\n",
    "                print(row['h_team'], row['a_team'], '==========================>>>>', data['h_team'], data['a_team'])\n",
    "                # Return NaN for rows with no match\n",
    "                return pd.Series([None,None, None, None])\n",
    "\n",
    "        # Apply the function to the 'rolled' DataFrame\n",
    "        rolled[['pts_bps','whh', 'whd', 'wha']] = rolled.apply(add_odds, axis=1, data=data)\n",
    "\n",
    "        # Save the updated DataFrame with the new columns\n",
    "        new_col_dir = './data/joint/'+ sns +'/merged_extras_odds/'\n",
    "        if not os.path.exists(new_col_dir):\n",
    "            os.makedirs(new_col_dir)\n",
    "        rolled.to_csv(new_col_dir + path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_files(season):\n",
    "    paths = next(os.walk('./data/joint/'+ season +'/merged_extras_odds', [None], [None],[]))[2]\n",
    "    files_list = [pd.read_csv('./data/joint/'+ season +'/merged_extras_odds/' + path)  for  path in paths ]\n",
    "    merged_files = pd.concat(files_list)\n",
    "\n",
    "    # Save the new DataFrame\n",
    "    new_col_dir = './data/joint/'+ season +'/'\n",
    "\n",
    "    merged_files.to_csv(new_col_dir  +'merged_player_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
