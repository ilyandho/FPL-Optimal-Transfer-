{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBRegressor as xgb\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# For the linear model\n",
    "def Linear_regression(features_train, features_test, target_train, target_test):\n",
    "    # Before using our data, we need to do feature scaling and we opt for the 'standardization' method of scaling.\n",
    "    # The 'standardization' is avaliable thorugh the StandardScaler() method\n",
    "    # Transformers help in batching tasks in a pipepline. In this case, the data is scaled and then a linear regression model is fitted on the scaled data.\n",
    "    # We use a transformer that takes the regression model and the transformation method\n",
    "    # The TransformedTargetRegressor does the transformation and when we do the prediction, it automatically does the inverse transformation (scaling) and returns the values\n",
    "    model = TransformedTargetRegressor(\n",
    "        LinearRegression(), transformer=StandardScaler())\n",
    "\n",
    "    # fit the transofrmer on the train data\n",
    "    model.fit(features_train, target_train)\n",
    "\n",
    "    # With the model fitted, we can predict the total_points given the feature_train and feature_test set\n",
    "    pred_train = model.predict(features_train)\n",
    "    pred_test = model.predict(features_test)\n",
    "\n",
    "    # Evaluate the performance of the model on both sets using the mean absolute error\n",
    "    train_MAE = mean_absolute_error(target_train, pred_train)\n",
    "    test_MAE = mean_absolute_error(target_test, pred_test)\n",
    "\n",
    "    # Evaluate the performance of the model on both sets using the mean square error\n",
    "    train_MSE = mean_squared_error(target_train, pred_train)\n",
    "    test_MSE = mean_squared_error(target_test, pred_test)\n",
    "\n",
    "    # Evaluate the performance of the model on both sets using the root mean square error\n",
    "    train_RMSE = mean_squared_error(target_train, pred_train, squared=False)\n",
    "    test_RMSE = mean_squared_error(target_test, pred_test, squared=False)\n",
    "\n",
    "    # Get the score of the model or the coeeficient of determination i.e how much of the target value can be explained by the model.\n",
    "    # In this case, 0.6 implies that 60% of the variations in the target value can be explained by the model and 40% is not explainable\n",
    "    R2_train = model.score(features_train, target_train)\n",
    "    R2_test = model.score(features_test, target_test)\n",
    "\n",
    "    # If the test error significantly differs from the train error, then there is either overfitting or underfitting\n",
    "    # RMSE, just like the squared loss function that it derives from, effectively penalizes larger errors more severely.\n",
    "    print('Training set RMSE: {}'.format(train_RMSE))\n",
    "    print('Test set RMSE: {}'.format(test_RMSE))\n",
    "\n",
    "    print('Training set R2: {}'.format(R2_train))\n",
    "    print('Test set R2: {}'.format(R2_test))\n",
    "\n",
    "    # Carry out cross validation of the model.\n",
    "    # The evaluation method is the root mean square error\n",
    "    # The method expects a utility function (greater is better) and so the scoring function is the opposite of the the RMSE. Hence the -ve\n",
    "    tree_rmses = -cross_val_score(model, features_train, target_train,\n",
    "                                  scoring=\"neg_root_mean_squared_error\", cv=10)\n",
    "\n",
    "    return {'train_MAE': train_MAE, 'test_MAE': test_MAE, 'train_MSE': train_MSE, 'test_MSE': test_MSE, 'train_RMSE': train_RMSE, 'test_RMSE': test_RMSE, 'cv_rmse': tree_rmses.mean(), 'R2_train': R2_train, 'R2_test': R2_test}\n",
    "\n",
    "\n",
    "# Decision Tree Model\n",
    "def DecisionTreeRegression(features_train, features_test, target_train, target_test):\n",
    "    # The DecisionTreeRegressor is passed as the model to the TransformedTreeRegressor together with the StandardScaler\n",
    "    model = TransformedTargetRegressor(\n",
    "        DecisionTreeRegressor(), transformer=StandardScaler())\n",
    "    model.fit(features_train, target_train)\n",
    "\n",
    "    pred_train = model.predict(features_train)\n",
    "    pred_test = model.predict(features_test)\n",
    "\n",
    "    train_MAE = mean_absolute_error(target_train, pred_train)\n",
    "    test_MAE = mean_absolute_error(target_test, pred_test)\n",
    "\n",
    "    train_MSE = mean_squared_error(target_train, pred_train)\n",
    "    test_MSE = mean_squared_error(target_test, pred_test)\n",
    "\n",
    "    train_RMSE = mean_squared_error(target_train, pred_train, squared=False)\n",
    "    test_RMSE = mean_squared_error(target_test, pred_test, squared=False)\n",
    "\n",
    "    R2_train = model.score(features_train, target_train)\n",
    "    R2_test = model.score(features_test, target_test)\n",
    "\n",
    "    tree_rmses = -cross_val_score(model, features_train, target_train,\n",
    "                                  scoring=\"neg_root_mean_squared_error\", cv=10)\n",
    "\n",
    "    return {'train_MAE': train_MAE, 'test_MAE': test_MAE, 'train_MSE': train_MSE, 'test_MSE': test_MSE,\n",
    "            'train_RMSE': train_RMSE, 'test_RMSE': test_RMSE, 'cv_rmse': tree_rmses.mean(), 'R2_train': R2_train, 'R2_test': R2_test}\n",
    "\n",
    "\n",
    "# RandomForestRegressor\n",
    "def RandomForestRegression(features_train, features_test, target_train, target_test, hyperparameters):\n",
    "    # RandomForestRegressor is an ensemble method\n",
    "    # The TransformedTargetRegressor is passed the RandomForestRegressor model\n",
    "    # The RandomForestRegressor is passed some hyper-parameters such as;\n",
    "    # n_esimtaors: number of trees in the forest,\n",
    "    # max_depth: the maximum depth of the tree,\n",
    "    # criterion: the function to measure the quality of the split\n",
    "\n",
    "    model = TransformedTargetRegressor(RandomForestRegressor(\n",
    "        n_estimators=hyperparameters['n_estimators'],  max_depth=hyperparameters['max_depth'], criterion=hyperparameters['criterion'], random_state=18), transformer=StandardScaler())\n",
    "    model.fit(features_train, target_train)\n",
    "\n",
    "    pred_train = model.predict(features_train)\n",
    "    pred_test = model.predict(features_test)\n",
    "\n",
    "    train_MAE = mean_absolute_error(target_train, pred_train)\n",
    "    test_MAE = mean_absolute_error(target_test, pred_test)\n",
    "\n",
    "    train_MSE = mean_squared_error(target_train, pred_train)\n",
    "    test_MSE = mean_squared_error(target_test, pred_test)\n",
    "\n",
    "    train_RMSE = mean_squared_error(target_train, pred_train, squared=False)\n",
    "    test_RMSE = mean_squared_error(target_test, pred_test, squared=False)\n",
    "\n",
    "    R2_train = model.score(features_train, target_train)\n",
    "    R2_test = model.score(features_test, target_test)\n",
    "\n",
    "    tree_rmses = -cross_val_score(model, features_train, target_train,\n",
    "                                  scoring=\"neg_root_mean_squared_error\", cv=10)\n",
    "\n",
    "    return {'train_MAE': train_MAE, 'test_MAE': test_MAE, 'train_MSE': train_MSE, 'test_MSE': test_MSE,\n",
    "            'train_RMSE': train_RMSE, 'test_RMSE': test_RMSE, 'cv_rmse': tree_rmses.mean(), 'R2_train': R2_train, 'R2_test': R2_test}\n",
    "\n",
    "\n",
    "def XGBoostRegression(features_train, features_test, target_train, target_test, hyperparameters):\n",
    "    regressor = xgb(learning_rate=hyperparameters[\"learning_rate\"],\n",
    "                    n_estimators=hyperparameters[\"n_estimators\"],\n",
    "                    max_depth=hyperparameters[\"max_depth\"],\n",
    "                    eval_metric='rmsle')\n",
    "\n",
    "    model = TransformedTargetRegressor(regressor, transformer=StandardScaler())\n",
    "\n",
    "\n",
    "    model.fit(features_train, target_train)\n",
    "\n",
    "    # =========================================================================\n",
    "    # To use early_stopping_rounds:\n",
    "    # \"Validation metric needs to improve at least once in every\n",
    "    # early_stopping_rounds round(s) to continue training.\"\n",
    "    # =========================================================================\n",
    "    # first perform a test/train split\n",
    "    # from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # X_train,X_test,y_train,y_test = train_test_split(X_train,y_train, test_size = 0.2)\n",
    "    # model.fit(X_train, y_train, early_stopping_rounds=6, eval_set=[(X_test, y_test)], verbose=False)\n",
    "\n",
    "    # =========================================================================\n",
    "    # use the model to predict the prices for the test data\n",
    "    # =========================================================================\n",
    "    # predictions = model.predict(goalkeepers_splits['feature_test'])\n",
    "\n",
    "    pred_train = model.predict(features_train)\n",
    "    pred_test = model.predict(features_test)\n",
    "\n",
    "    train_MAE = mean_absolute_error(target_train, pred_train)\n",
    "    test_MAE = mean_absolute_error(target_test, pred_test)\n",
    "\n",
    "    train_MSE = mean_squared_error(target_train, pred_train)\n",
    "    test_MSE = mean_squared_error(target_test, pred_test)\n",
    "\n",
    "    train_RMSE = mean_squared_error(target_train, pred_train, squared=False)\n",
    "    test_RMSE = mean_squared_error(target_test, pred_test, squared=False)\n",
    "\n",
    "    R2_train = model.score(features_train, target_train)\n",
    "    R2_test = model.score(features_test, target_test)\n",
    "\n",
    "    tree_rmses = -cross_val_score(model, features_train, target_train,\n",
    "                                  scoring=\"neg_root_mean_squared_error\", cv=10)\n",
    "\n",
    "    return {'train_MAE': train_MAE, 'test_MAE': test_MAE, 'train_MSE': train_MSE, 'test_MSE': test_MSE,\n",
    "            'train_RMSE': train_RMSE, 'test_RMSE': test_RMSE, 'cv_rmse': tree_rmses.mean(), 'R2_train': R2_train, 'R2_test': R2_test}\n",
    "\n",
    "\n",
    "def GridSearchParams(features_train, target_train):\n",
    "    # Instatiate the model\n",
    "    model = RandomForestRegressor()\n",
    "\n",
    "    param_grid = {'n_estimators': [8, 10, 12, 14, 16, 18, 20]}\n",
    "\n",
    "    # Define the possible values of the hyperparameter\n",
    "    grid = {\n",
    "        'n_estimators': [8, 10, 12, 14, 16, 18, 20, 200, 300, 400, 500],\n",
    "        'max_features': ['sqrt', 'log2'],\n",
    "        'max_depth': [4, 5, 6, 7, 8],\n",
    "        'criterion': ['squared_error', 'absolute_error', 'friedman_mse', 'poisson'],\n",
    "        'random_state': [18]\n",
    "    }\n",
    "\n",
    "    # Deine the model with cv=3 for a 3-fold cross validation\n",
    "    # GridSearchCV has the best_estimator_ parameter that returns the  estimator\n",
    "    # which gave highest score (or smallest loss if specified)\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        model, grid, cv=3, scoring='neg_root_mean_squared_error')\n",
    "    grid_search.fit(features_train, target_train)\n",
    "\n",
    "    # Get the best param combination\n",
    "    print(grid_search.best_estimator_)\n",
    "\n",
    "    return {'train_RMSE': train_RMSE, 'test_RMSE': test_RMSE, 'R2_train': R2_train, 'R2_test': R2_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define a function that splits and returns features_train, features_test, target_train, target_test\n",
    "\n",
    "def split_data(data):\n",
    "    # Store the 'total_points' target in the 'player_target' variable\n",
    "    # and the rest in the player_features variable\n",
    "    player_target = data['pts_bps']\n",
    "    player_features = data.drop(\"pts_bps\", axis=1)\n",
    "\n",
    "    # The train_test_split function splits the set into train and test sets while maintain the same data distribution over both sets.\n",
    "    # It takes the feature and target sets and reutrns the respective train and test sets\n",
    "    features_train, features_test, target_train, target_test = train_test_split(\n",
    "        player_features, player_target, test_size=0.2)\n",
    "\n",
    "    return {'feature_train': features_train, 'features_test': features_test, 'target_train': target_train, 'target_test': target_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "    Total Points – Bonus Points (tp-bp), Minutes, Yellow Cards, Red Cards, Expected Goals (xG), Expected Assists (xA), Non-penalty Expected Goals (npxG),\n",
    "    Shots, Expected Goals Against, _Expected_goal_involvements_,  clean_sheets, ict_index, opponent_team, Expected Goals Buildup (xG Buildup), threat, value,\n",
    "    Key Passes,\n",
    "\n",
    "\n",
    "    _Games_,  Expected Goals Chain (xG Chain),  _Non-penalty Expected Goal Difference (npxGD)_, _Non-penalty Expected Goals Against (npxGA)_, Expected Points (xPts)\n",
    "```\n",
    "\n",
    "```js\n",
    "    Total Points – Bonus Points (tp-bp)\tfor, mid, def, gk\n",
    "    Minutes\tfor, mid, def, gk\n",
    "    Yellow Cards\tfor, mid, def, gk\n",
    "    Red Cards\tfor, mid, def, gk\n",
    "    Expected Goals (xG)\tfor, mid, def, gk\n",
    "    Expected Assists (xA)\tfor, mid, def, gk\n",
    "    Non-penalty Expected Goals (npxG)\tfor, mid, def\n",
    "    Games\tfor, mid, def, gk\n",
    "    Shots\tfor, mid, def\n",
    "    Key Passes\tfor, mid, def, gk\n",
    "    Expected Goals Chain (xG Chain)\tfor, mid, def\n",
    "    Expected Goals Buildup (xG Buildup)\tfor, mid, def\n",
    "    Non-penalty Expected Goal Difference (npxGD)\tdef, gk\n",
    "    Expected Goals Against\tdef, gk\n",
    "    Non-penalty Expected Goals Against (npxGA)\tdef, gk\n",
    "    Expected Points (xPts)\tdef, gk\n",
    "    expected_goal_involvements\tfor, mid, def, gk\n",
    "    clean_sheets\tmid, def, gk\n",
    "    ict_index\tfor, mid, def, gk\n",
    "    opponent_team\tfor, mid, def, gk\n",
    "    threat\tfor, mid, def, gk\n",
    "    value\tfor, mid, def, gk\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'total_points', 'bonus', 'minutes', 'yellow_cards', 'red_cards', 'expected_goals', 'expected_assists', 'npxG', 'shots', 'expected_goal_involvements', 'expected_goals_conceded', 'clean_sheets', 'ict_index',\n",
    "    'xGBuildup', 'threat', 'value', 'key_passes', 'xGChain', 'xP', 'team_h_difficulty', 'team_a_difficulty', 'was_home', 'position']\n",
    "\n",
    "gk_cols = [\n",
    "            'pts_bps', 'minutes', 'yellow_cards', 'red_cards', 'expected_goals', 'expected_assists', 'expected_goal_involvements', 'expected_goals_conceded', 'clean_sheets', 'ict_index',\n",
    "            'threat', 'value', 'key_passes', 'xP', 'team_h_difficulty', 'team_a_difficulty', 'was_home']\n",
    "def_cols = [\n",
    "            'pts_bps', 'minutes', 'yellow_cards', 'red_cards', 'expected_goals', 'expected_assists', 'npxG', 'shots', 'expected_goal_involvements', 'expected_goals_conceded', 'clean_sheets', 'ict_index',\n",
    "            'xGBuildup', 'threat', 'value', 'key_passes', 'xGChain', 'xP', 'team_h_difficulty', 'team_a_difficulty', 'was_home',\n",
    "]\n",
    "mid_cols = [\n",
    "            'pts_bps', 'minutes', 'yellow_cards', 'red_cards', 'expected_goals', 'expected_assists', 'npxG', 'shots', 'expected_goal_involvements', 'clean_sheets', 'ict_index',\n",
    "            'xGBuildup', 'threat', 'value', 'key_passes', 'xGChain', 'xP', 'team_h_difficulty', 'team_a_difficulty', 'was_home',\n",
    "]\n",
    "fwd_cols = [\n",
    "            'pts_bps', 'minutes', 'yellow_cards', 'red_cards', 'expected_goals', 'expected_assists', 'npxG', 'shots', 'expected_goal_involvements', 'ict_index',\n",
    "            'xGBuildup', 'threat', 'value', 'key_passes', 'xGChain', 'xP', 'team_h_difficulty', 'team_a_difficulty', 'was_home',\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# player_21_22 = pd.read_csv('./data/joint/21-22/merged_player_data.csv')[columns]\n",
    "player_22_23 = pd.read_csv('./data/joint/22-23/merged_player_data.csv')[columns]\n",
    "player_23_24 = pd.read_csv('./data/joint/23-24/merged_player_data.csv')[columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter out players with zero points\n",
    "player_22_23_no = player_22_23[player_22_23['total_points'] !=0]\n",
    "player_23_24_no = player_23_24[player_23_24['total_points'] !=0]\n",
    "\n",
    "player_data = pd.concat([player_22_23_no, player_23_24_no])\n",
    "\n",
    "def points_(row):\n",
    "    return row['total_points'] - row['bonus']\n",
    "player_data['pts_bps'] = player_data.apply(points_, axis=1)\n",
    "player_data = player_data.drop(['total_points', 'bonus'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by position\n",
    "gk_player_data = player_data[player_data['position']=='GK']\n",
    "gk_player_data = gk_player_data.drop('position', axis=1)\n",
    "gk_player_data = gk_player_data[gk_cols]\n",
    "\n",
    "def_player_data = player_data[player_data['position']=='DEF']\n",
    "def_player_data = def_player_data.drop('position', axis=1)\n",
    "def_player_data = def_player_data[def_cols]\n",
    "\n",
    "mid_player_data = player_data[player_data['position']=='MID']\n",
    "mid_player_data = mid_player_data.drop('position', axis=1)\n",
    "mid_player_data = mid_player_data[mid_cols]\n",
    "\n",
    "fwd_player_data = player_data[player_data['position']=='FWD']\n",
    "fwd_player_data = fwd_player_data.drop('position', axis=1)\n",
    "fwd_player_data = fwd_player_data[fwd_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run ./goalkeepers.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FPL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
