{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from thefuzz import fuzz, process\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Util functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fpl_players(fpl_subfolders, season):\n",
    "\n",
    "    for folder in fpl_subfolders:\n",
    "        # print(folder)\n",
    "        # print('flp: ', folder)\n",
    "        player_name = folder.split('/')[6].split('_')\n",
    "        clean_player_name = \" \".join(player_name[0:-1])\n",
    "        player_df = pd.read_csv(str(folder+'/gw.csv'))\n",
    "        player_dir = './data/joint/'+str(season)+'/fpl/'\n",
    "         # Check if player_dir exists\n",
    "\n",
    "\n",
    "        if not os.path.exists(player_dir):\n",
    "            os.makedirs(player_dir)\n",
    "        player_df.to_csv(player_dir + str(clean_player_name) + '.csv', index_label=False)\n",
    "\n",
    "    print('successfully cleaned 20'+ season +' fpl data')\n",
    "\n",
    "# Understat Files\n",
    "def save_under_players(understat_files, season):\n",
    "    for file_ in understat_files:\n",
    "        player_name = file_.split('/')[6].split('_')\n",
    "        clean_player_name = \" \".join(player_name[0:-1])\n",
    "        player_df = pd.read_csv(str(file_))\n",
    "\n",
    "        player_dir = './data/joint/'+str(season)+'/understat/'\n",
    "        # Check if player_dir exists\n",
    "        if not os.path.exists(player_dir):\n",
    "            os.makedirs(player_dir)\n",
    "        player_df.to_csv(player_dir + str(clean_player_name) + '.csv', index_label=False)\n",
    "\n",
    "    print('successfully cleaned understat 20'+ season +' data')\n",
    "\n",
    "def joint_players_info(fpl_player_folder_path, understat_player_folder_path, season):\n",
    "    fpl_subfolders = [ f.path for f in os.scandir(fpl_player_folder_path) if f.is_dir() ]\n",
    "    under_files = [ f.path for f in os.scandir(understat_player_folder_path) if f.is_file() ]\n",
    "\n",
    "    save_fpl_players(fpl_subfolders, season)\n",
    "    save_under_players(under_files, season)\n",
    "\n",
    "    print('20'+ season +' fpl and understat data now in `joint` folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_fpl_understat_data(fpl_player_folder_path, understat_player_folder_path, season):\n",
    "    joint_players_info(fpl_player_folder_path, understat_player_folder_path, season)\n",
    "\n",
    "    joint_fpl_data_path = \"./data/joint/\"+ season + \"/fpl/\"\n",
    "    joint_understat_path = \"./data/joint/\"+ season + \"/understat/\"\n",
    "\n",
    "    understat_files= next(os.walk(\"./data/joint/\"+ season + \"/understat/\"), (None, None, []))[2]  # [] if no file\n",
    "    fpl_files = next(os.walk( \"./data/joint/\"+ season +\"/fpl\"), (None, None, []))[2]  # [] if no file\n",
    "    player_ids = pd.read_csv('./data/id_dict_'+ season +'.csv')  #('./data/20'+ season +'/id_dict.csv')\n",
    "\n",
    "    understat_names = [file_.split('.')[0] for file_ in understat_files]\n",
    "    fpl_file_names = [file_.split('.')[0] for file_ in fpl_files]\n",
    "    for name in fpl_file_names:\n",
    "        fpl_player = player_ids[player_ids['FPL_Name'] == name]\n",
    "        fpl_player['FPL_Name'].values\n",
    "\n",
    "        if fpl_player['FPL_Name'].values.size > 0:\n",
    "            fpl_player_name = fpl_player['FPL_Name'].values[0]\n",
    "            understat_player_name = fpl_player['Understat_Name'].values[0]\n",
    "\n",
    "            fpl_player_data = pd.read_csv(joint_fpl_data_path + fpl_player_name+ '.csv')\n",
    "            understat_player_data = pd.read_csv(joint_understat_path + understat_player_name + '.csv')\n",
    "\n",
    "            # Change 'kickoff_time' column name to 'date\n",
    "            fpl_player_data = fpl_player_data.rename(columns={'kickoff_time': 'date'})\n",
    "            # change the formats: From 2021-10-03T13:00:00Z to 2021-10-03\n",
    "            fpl_player_data.date = fpl_player_data.date.apply(lambda x: x.split('T')[0])\n",
    "\n",
    "            # Dates are of the form 2021-10-03T13:00:00Z\n",
    "            fpl_dates_min = fpl_player_data['date'].min()\n",
    "            fpl_dates_max = fpl_player_data['date'].max()\n",
    "\n",
    "\n",
    "            # Filter out player info not in the range of dates we are dealing with\n",
    "            understat_filtered = understat_player_data[(pd.to_datetime(understat_player_data['date']) >= pd.to_datetime(fpl_dates_min))\n",
    "                                                        & (pd.to_datetime(understat_player_data['date']) <= pd.to_datetime(fpl_dates_max) )]\n",
    "\n",
    "            # Marge fpl_player_data with understat_player_data if the dates match\n",
    "            player_data_merged = fpl_player_data.merge(understat_filtered, on=\"date\")\n",
    "\n",
    "            # Add player team\n",
    "            def set_player_team(row):\n",
    "                return row['h_team'] if row['was_home'] else row['a_team']\n",
    "\n",
    "            with_team = player_data_merged.apply(set_player_team, axis=1)\n",
    "            player_data_merged['player_team'] = player_data_merged.apply(set_player_team, axis=1)\n",
    "\n",
    "\n",
    "            if(player_data_merged.shape[0]):\n",
    "                merged_dir = './data/joint/'+ season +'/merged/'\n",
    "                if not os.path.exists(merged_dir):\n",
    "                    os.makedirs(merged_dir)\n",
    "\n",
    "                player_data_merged.to_csv(merged_dir+ fpl_player_name +'.csv', index_label=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_difficulty(season):\n",
    "    print('====> Starting to add difficulty features to 20'+season)\n",
    "    merged = './data/joint/' + season + '/merged/'\n",
    "\n",
    "    player_names = next(os.walk((merged), (None, None, [])))[2]\n",
    "    fixtures = pd.read_csv('./data/20' + season + '/fixtures.csv')\n",
    "\n",
    "    # Loop over each player file in player_names\n",
    "    for name in player_names:\n",
    "        # Load player data\n",
    "        player = pd.read_csv('./data/joint/' + season + '/merged/' + name)\n",
    "\n",
    "        # Function to get the difficulty and was_home columns based on the fixture\n",
    "        def get_fixture_info(row):\n",
    "            # Filter the relevant fixture\n",
    "            fixture = fixtures[fixtures['id'] == row['fixture']]\n",
    "            if not fixture.empty:\n",
    "                fixture = fixture.iloc[0]  # Get the first (and only) match\n",
    "\n",
    "                # Get the team difficulties\n",
    "                team_h_difficulty = fixture['team_h_difficulty']\n",
    "                team_a_difficulty = fixture['team_a_difficulty']\n",
    "                event = fixture['event']\n",
    "\n",
    "                return pd.Series([team_h_difficulty, team_a_difficulty, event])\n",
    "            else:\n",
    "                # Return NaN if no matching fixture found\n",
    "                return pd.Series([None, None, None])\n",
    "\n",
    "        # Apply the function to each row of player\n",
    "        player[['team_h_difficulty', 'team_a_difficulty', 'event']] = player.apply(get_fixture_info, axis=1)\n",
    "\n",
    "\n",
    "        # Save the updated DataFrame with the new columns\n",
    "        new_col_dir = './data/joint/' + season + '/merged_extras/'\n",
    "        if not os.path.exists(new_col_dir):\n",
    "            os.makedirs(new_col_dir)\n",
    "        player.to_csv(new_col_dir + name, index=False)\n",
    "\n",
    "    # print(player[player['round']== 10])\n",
    "    print('****> successfully added difficulty features to 20'+season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_xP(season, gwk=None):\n",
    "    print('================> starting season 20'+season)\n",
    "    players_paths = next(os.walk('./data/joint/'+ season +'/merged_extras', [None], [None],[]))[2]\n",
    "    # players_paths\n",
    "    for path in players_paths:\n",
    "        player = pd.read_csv('./data/joint/'+ season +'/merged_extras/'+ path)\n",
    "        merged = pd.read_csv('./data/20'+ season +'/gws/merged_gw.csv')\n",
    "\n",
    "        player = player.drop(['position'], axis=1)\n",
    "        merged_player = pd.merge(player, merged[['element', 'fixture', 'xP','position']], on=['element', 'fixture'], how='left')\n",
    "\n",
    "\n",
    "        if gwk:\n",
    "            merged_player = merged_player.reindex(merged_player.index.tolist()  + list([merged_player.index[-1]+1]))\n",
    "            merged_player.iloc[-1, merged_player.columns.get_loc('event')] = gwk\n",
    "\n",
    "\n",
    "        # Save the updated DataFrame with the new columns\n",
    "        new_col_dir = './data/joint/'+ season +'/merged_extras_xP/'\n",
    "        if not os.path.exists(new_col_dir):\n",
    "            os.makedirs(new_col_dir)\n",
    "        merged_player.to_csv(new_col_dir + path, index=False)\n",
    "\n",
    "    print('<<<<================ starting season 20'+season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rolling_avgs_3(season):\n",
    "    print('================> starting season 20'+season)\n",
    "    players_paths = next(os.walk('./data/joint/'+ season +'/merged_extras_xP', [None], [None],[]))[2]\n",
    "    for path in players_paths:\n",
    "        player = pd.read_csv('./data/joint/'+ season +'/merged_extras_xP/'+ path,sep=',', skipinitialspace=True)\n",
    "\n",
    "        prev = [\n",
    "                [0 for i in range(34)],\n",
    "                [0 for i in range(34)],\n",
    "                [0 for i in range(34)],\n",
    "                [0 for i in range(34)]\n",
    "            ]\n",
    "        gwks = [1]\n",
    "\n",
    "        features = ['clean_sheets', 'expected_assists', 'expected_goal_involvements', 'expected_goals', 'expected_goals_conceded', 'goals_conceded', 'goals_scored', 'ict_index',\n",
    "                    'influence', 'creativity', 'threat', 'minutes', 'own_goals', 'penalties_missed', 'penalties_saved', 'red_cards', 'yellow_cards', 'saves', 'starts',\n",
    "                    'team_a_score', 'team_h_score', 'total_points', 'goals', 'shots', 'xG', 'xA', 'assists_y', 'key_passes', 'npg', 'npxG', 'xGChain',  'xGBuildup',  'xP', 'selected'\n",
    "                    ]\n",
    "\n",
    "        def rolling(row):\n",
    "            row_items = [row.get(col, 0) for col in features]\n",
    "\n",
    "            if row['event'] - gwks[0] == 0:\n",
    "                del prev[3]\n",
    "                prev.append(row_items)\n",
    "\n",
    "            elif row['event'] - gwks[0] == 1:\n",
    "                del prev[0]\n",
    "                prev.append(row_items)\n",
    "                gwks[0] = row['event']\n",
    "\n",
    "            elif row['event'] - gwks[0] == 2:\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append(row_items)\n",
    "                gwks[0] = row['event']\n",
    "\n",
    "            else:\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append(row_items)\n",
    "                gwks[0] = row['event']\n",
    "\n",
    "            # print(row['event'], len(pd.Series([round((x+y+z)/3 ,2) for x,y,z in zip(prev[0], prev[1], prev[2])])),  prev[0], prev[1], prev[2], prev[3]) #\n",
    "            return pd.Series([round((x+y+z) ,2) for x,y,z in zip(prev[0], prev[1], prev[2])])\n",
    "        player[[f\"{col}_3\" for col in features]] = player.apply(rolling, axis=1)\n",
    "\n",
    "        # if curr_sns:\n",
    "        #     tar_wk = pd.Series([round((x+y+z) ,2) for x,y,z in zip(prev[1], prev[2], prev[3])])\n",
    "        #     print( tar_wk )\n",
    "\n",
    "        # Save the updated DataFrame with the new columns\n",
    "        new_col_dir = f'./data/joint/{season}/merged_extras_rolled_3/'\n",
    "        if not os.path.exists(new_col_dir):\n",
    "            os.makedirs(new_col_dir)\n",
    "        player.to_csv(new_col_dir + path, index=False)\n",
    "\n",
    "    print('<<<<================ starting season 20'+season)\n",
    "\n",
    "def add_rolling_avgs_5(season):\n",
    "    print('================> starting season 20'+season)\n",
    "    players_paths = next(os.walk('./data/joint/'+ season +'/merged_extras_rolled_3', [None], [None],[]))[2]\n",
    "    for path in players_paths:\n",
    "        player = pd.read_csv('./data/joint/'+ season +'/merged_extras_rolled_3/'+ path,sep=',', skipinitialspace=True)\n",
    "\n",
    "        prev = [\n",
    "                [0 for i in range(34)],\n",
    "                [0 for i in range(34)],\n",
    "                [0 for i in range(34)],\n",
    "                [0 for i in range(34)],\n",
    "                [0 for i in range(34)],\n",
    "                [0 for i in range(34)]\n",
    "            ]\n",
    "        gwks = [1]\n",
    "\n",
    "        features = ['clean_sheets', 'expected_assists', 'expected_goal_involvements', 'expected_goals', 'expected_goals_conceded', 'goals_conceded', 'goals_scored', 'ict_index',\n",
    "                    'influence', 'creativity', 'threat', 'minutes', 'own_goals', 'penalties_missed', 'penalties_saved', 'red_cards', 'yellow_cards', 'saves', 'starts',\n",
    "                    'team_a_score', 'team_h_score', 'total_points', 'goals', 'shots', 'xG', 'xA', 'assists_y', 'key_passes', 'npg', 'npxG', 'xGChain',  'xGBuildup',  'xP', 'selected'\n",
    "                    ]\n",
    "\n",
    "        def rolling(row):\n",
    "            row_items = [row.get(col, 0) for col in features]\n",
    "\n",
    "            if row['event'] - gwks[0]== 0:\n",
    "                del prev[5]\n",
    "                prev.append(row_items)\n",
    "\n",
    "            elif row['event'] - gwks[0] == 1:\n",
    "                del prev[0]\n",
    "                prev.append(row_items)\n",
    "                gwks[0] = row['event']\n",
    "\n",
    "            elif row['event'] - gwks[0] == 2:\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append(row_items)\n",
    "                gwks[0] = row['event']\n",
    "\n",
    "            elif row['event'] - gwks[0] == 3:\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append(row_items)\n",
    "                gwks[0] = row['event']\n",
    "\n",
    "            elif row['event'] - gwks[0] == 4:\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append(row_items)\n",
    "                gwks[0] = row['event']\n",
    "            else:\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                del prev[0]\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append([0 for i in range(34)])\n",
    "                prev.append(row_items)\n",
    "                gwks[0] = row['event']\n",
    "\n",
    "            return pd.Series([round((v+w+x+y+z) ,2) for v, w, x,y,z in zip(prev[0], prev[1], prev[2], prev[3], prev[4])])\n",
    "        player[[f\"{col}_5\" for col in features]] = player.apply(rolling, axis=1)\n",
    "        print(player)\n",
    "\n",
    "        # Save the updated DataFrame with the new columns\n",
    "        new_col_dir = f'./data/joint/{season}/merged_extras_rolled_5/'\n",
    "        if not os.path.exists(new_col_dir):\n",
    "            os.makedirs(new_col_dir)\n",
    "        player.to_csv(new_col_dir + path, index=False)\n",
    "\n",
    "def add_rolling_avgs(season):\n",
    "    add_rolling_avgs_3(season)\n",
    "    add_rolling_avgs_5(season)\n",
    "\n",
    "    print('<<<<================ Done rolling season 20'+season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odds(sns, nxt_gw=0):\n",
    "    print('================> starting sns 20'+sns)\n",
    "    # Load the data data once to avoid redundant file reads\n",
    "    data = pd.read_csv('./data/odds/E0 '+ sns +'.csv')\n",
    "    data = data.rename(columns={'HomeTeam': 'h_team', 'AwayTeam': 'a_team'})\n",
    "\n",
    "    players_paths = next(os.walk('./data/joint/'+ sns +'/merged_extras_rolled_5', [None], [None],[]))[2]\n",
    "    for path in players_paths:\n",
    "        rolled = pd.read_csv('./data/joint/'+ sns +'/merged_extras_rolled_5/'+ path,sep=',', skipinitialspace=True)\n",
    "\n",
    "        def add_odds(row, data):\n",
    "            # Filter the data DataFrame for the matching teams\n",
    "            match = data[(data['h_team'] == row['h_team']) & (data['a_team'] == row['a_team'])]\n",
    "            # Check if a match is found\n",
    "\n",
    "            if not match.empty:\n",
    "                # Extract the relevant data values\n",
    "                # Convert the data to probabilities\n",
    "                odds_ = match.iloc[0]\n",
    "\n",
    "                WHH = round(1/odds_['WHH'], 5)\n",
    "                WHD = round(1/odds_['WHD'], 5)\n",
    "                WHA = round(1/odds_['WHA'], 5)\n",
    "\n",
    "                # Normalize the probabilities (to make the probabilities sum to 100%)\n",
    "                WH_sum = WHH + WHD + WHA\n",
    "                WHH_ = round(WHH/WH_sum, 3)\n",
    "                WHD_ = round(WHD/WH_sum, 3)\n",
    "                WHA_ = round(WHA/WH_sum, 3)\n",
    "\n",
    "                pts_bps = row['total_points'] - row['bonus']\n",
    "                return pd.Series([pts_bps, WHH_, WHD_, WHA_])\n",
    "            else:\n",
    "                # print(row['h_team'], row['a_team'], '==========================>>>>', data['h_team'], data['a_team'])\n",
    "                # Return NaN for rows with no match\n",
    "                return pd.Series([None,None, None, None])\n",
    "\n",
    "        # Apply the function to the 'rolled' DataFrame\n",
    "        rolled[['pts_bps','whh', 'whd', 'wha']] = rolled.apply(add_odds, axis=1, data=data)\n",
    "\n",
    "        if nxt_gw:\n",
    "            odds_nxt = pd.read_csv(f'./data/odds/odds_{nxt_gw}.csv')\n",
    "            opp_team = rolled['opponent_team']\n",
    "\n",
    "            player_team = rolled['player_team'].loc[0]\n",
    "\n",
    "            team_odds_nxt = odds_nxt[(odds_nxt['h_team'] == player_team) | (odds_nxt['a_team']==player_team)]\n",
    "            h_team = team_odds_nxt.loc[:, 'h_team'].values[0]\n",
    "            a_team = team_odds_nxt.loc[:, 'a_team'].values[0]\n",
    "            whh = team_odds_nxt.loc[:,'WHH'].values[0]\n",
    "            whd = team_odds_nxt.loc[:,'WHD'].values[0]\n",
    "            wha = team_odds_nxt.loc[:,'WHA'].values[0]\n",
    "            h_fdr = team_odds_nxt.loc[:,'h_fdr'].values[0]\n",
    "            a_fdr = team_odds_nxt.loc[:,'a_fdr'].values[0]\n",
    "\n",
    "            was_home = True if h_team == player_team else False\n",
    "\n",
    "            rolled.iloc[-1, rolled.columns.get_loc('whh')] = whh\n",
    "            rolled.iloc[-1, rolled.columns.get_loc('whd')] = whd\n",
    "            rolled.iloc[-1, rolled.columns.get_loc('wha')] = wha\n",
    "            rolled.iloc[-1, rolled.columns.get_loc('was_home')] = was_home\n",
    "            rolled.iloc[-1, rolled.columns.get_loc('h_team')] = h_team\n",
    "            rolled.iloc[-1, rolled.columns.get_loc('a_team')] = a_team\n",
    "            rolled.iloc[-1, rolled.columns.get_loc('team_h_difficulty')] = h_fdr\n",
    "            rolled.iloc[-1, rolled.columns.get_loc('team_a_difficulty')] = a_fdr\n",
    "\n",
    "        # Save the updated DataFrame with the new columns\n",
    "        new_col_dir = './data/joint/'+ sns +'/merged_extras_odds/'\n",
    "        if not os.path.exists(new_col_dir):\n",
    "            os.makedirs(new_col_dir)\n",
    "        rolled.to_csv(new_col_dir + path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_files(season):\n",
    "    paths = next(os.walk('./data/joint/'+ season +'/merged_extras_odds', [None], [None],[]))[2]\n",
    "    files_list = [pd.read_csv('./data/joint/'+ season +'/merged_extras_odds/' + path)  for  path in paths ]\n",
    "    merged_files = pd.concat(files_list)\n",
    "\n",
    "    # Save the new DataFrame\n",
    "    new_col_dir = './data/joint/'+ season +'/'\n",
    "\n",
    "    merged_files.to_csv(new_col_dir  +'merged_player_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
