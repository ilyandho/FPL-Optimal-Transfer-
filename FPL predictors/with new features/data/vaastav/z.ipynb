{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsers import *\n",
    "from cleaners import *\n",
    "from getters import *\n",
    "from collector import collect_gw, merge_gw\n",
    "from understat import parse_epl_data\n",
    "import csv\n",
    "\n",
    "def parse_data():\n",
    "    \"\"\" Parse and store all the data\n",
    "    \"\"\"\n",
    "    season = '2024-25'\n",
    "    base_filename = 'data/' + season + '/'\n",
    "    print(\"Getting data\")\n",
    "    data = get_data()\n",
    "    print(\"Parsing summary data\")\n",
    "    parse_players(data[\"elements\"], base_filename)\n",
    "    xPoints = []\n",
    "    for e in data[\"elements\"]:\n",
    "        xPoint = {}\n",
    "        xPoint['id'] = e['id']\n",
    "        xPoint['xP'] = e['ep_this']\n",
    "        xPoints += [xPoint]\n",
    "    gw_num = 0\n",
    "    events = data[\"events\"]\n",
    "    for event in events:\n",
    "        if event[\"is_current\"] == True:\n",
    "            gw_num = event[\"id\"]\n",
    "    print(\"Cleaning summary data\")\n",
    "    clean_players(base_filename + 'players_raw.csv', base_filename)\n",
    "    print(\"Getting fixtures data\")\n",
    "    fixtures(base_filename)\n",
    "    print(\"Getting teams data\")\n",
    "    parse_team_data(data[\"teams\"], base_filename)\n",
    "    print(\"Extracting player ids\")\n",
    "    id_players(base_filename + 'players_raw.csv', base_filename)\n",
    "    player_ids = get_player_ids(base_filename)\n",
    "    num_players = len(data[\"elements\"])\n",
    "    player_base_filename = base_filename + 'players/'\n",
    "    gw_base_filename = base_filename + 'gws/'\n",
    "    print(\"Extracting player specific data\")\n",
    "    for i,name in player_ids.items():\n",
    "        player_data = get_individual_player_data(i)\n",
    "        parse_player_history(player_data[\"history_past\"], player_base_filename, name, i)\n",
    "        parse_player_gw_history(player_data[\"history\"], player_base_filename, name, i)\n",
    "    if gw_num > 0:\n",
    "        print(\"Writing expected points\")\n",
    "        with open(os.path.join(gw_base_filename, 'xP' + str(gw_num) + '.csv'), 'w+') as outf:\n",
    "            w = csv.DictWriter(outf, ['id', 'xP'])\n",
    "            w.writeheader()\n",
    "            for xp in xPoints:\n",
    "                w.writerow(xp)\n",
    "        print(\"Collecting gw scores\")\n",
    "        collect_gw(gw_num, player_base_filename, gw_base_filename, base_filename)\n",
    "        print(\"Merging gw scores\")\n",
    "        merge_gw(gw_num, gw_base_filename)\n",
    "    understat_filename = base_filename + 'understat'\n",
    "    parse_epl_data(understat_filename)\n",
    "\n",
    "def fixtures(base_filename):\n",
    "    data = get_fixtures_data()\n",
    "    parse_fixtures(data, base_filename)\n",
    "\n",
    "def main():\n",
    "    parse_data()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from utility import uprint\n",
    "import pandas as pd\n",
    "\n",
    "def extract_stat_names(dict_of_stats):\n",
    "    \"\"\" Extracts all the names of the statistics\n",
    "\n",
    "    Args:\n",
    "        dict_of_stats (dict): Dictionary containing key-alue pair of stats\n",
    "    \"\"\"\n",
    "    stat_names = []\n",
    "    for key, val in dict_of_stats.items():\n",
    "        stat_names += [key]\n",
    "    return stat_names\n",
    "\n",
    "def parse_top_players(data, base_filename):\n",
    "    rows = []\n",
    "    for event in data['events']:\n",
    "        gw = event['id']\n",
    "        player_id = event['top_element']\n",
    "        points = event['top_element_info']['points']\n",
    "        row = {}\n",
    "        row['gw'] = gw\n",
    "        row['player_id'] = player_id\n",
    "        row['points'] = points\n",
    "        rows += [row]\n",
    "    f = open(os.path.join(base_filename, 'best_players.csv'), 'w+', newline='')\n",
    "    w = csv.DictWriter(f, ['gw', 'player_id', 'points'])\n",
    "    w.writeheader()\n",
    "    for row in rows:\n",
    "        w.writerow(row)\n",
    "\n",
    "def parse_players(list_of_players, base_filename):\n",
    "    stat_names = extract_stat_names(list_of_players[0])\n",
    "    filename = base_filename + 'players_raw.csv'\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    f = open(filename, 'w+', encoding='utf8', newline='')\n",
    "    w = csv.DictWriter(f, sorted(stat_names))\n",
    "    w.writeheader()\n",
    "    for player in list_of_players:\n",
    "            w.writerow({k:str(v).encode('utf-8').decode('utf-8') for k, v in player.items()})\n",
    "\n",
    "def parse_player_history(list_of_histories, base_filename, player_name, Id):\n",
    "    if len(list_of_histories) > 0:\n",
    "        stat_names = extract_stat_names(list_of_histories[0])\n",
    "        filename = base_filename + player_name + '_' + str(Id) + '/history.csv'\n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "        f = open(filename, 'w+', encoding='utf8', newline='')\n",
    "        w = csv.DictWriter(f, sorted(stat_names))\n",
    "        w.writeheader()\n",
    "        for history in list_of_histories:\n",
    "            w.writerow(history)\n",
    "\n",
    "def parse_player_gw_history(list_of_gw, base_filename, player_name, Id):\n",
    "    if len(list_of_gw) > 0:\n",
    "        stat_names = extract_stat_names(list_of_gw[0])\n",
    "        filename = base_filename + player_name + '_' + str(Id) + '/gw.csv'\n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "        f = open(filename, 'w+', encoding='utf8', newline='')\n",
    "        w = csv.DictWriter(f, sorted(stat_names))\n",
    "        w.writeheader()\n",
    "        for gw in list_of_gw:\n",
    "            w.writerow(gw)\n",
    "\n",
    "def parse_gw_entry_history(data, outfile_base):\n",
    "    for gw in data:\n",
    "        picks = gw['picks']\n",
    "        event = gw['entry_history']['event']\n",
    "        filename = \"picks_\" +str(event) + \".csv\"\n",
    "        picks_df = pd.DataFrame.from_records(picks)\n",
    "        picks_df.to_csv(os.path.join(outfile_base, filename), index=False)\n",
    "\n",
    "def parse_entry_history(data, outfile_base):\n",
    "    chips_df = pd.DataFrame.from_records(data[\"chips\"])\n",
    "    chips_df.to_csv(os.path.join(outfile_base, 'chips.csv'), index=False)\n",
    "    season_df = pd.DataFrame.from_records(data[\"past\"])\n",
    "    season_df.to_csv(os.path.join(outfile_base, 'history.csv'), index=False)\n",
    "    #profile_data = data[\"entry\"].pop('kit', data[\"entry\"])\n",
    "    #profile_df = pd.DataFrame.from_records(profile_data)\n",
    "    #profile_df.to_csv(os.path.join(outfile_base, 'profile.csv'), index=False)\n",
    "    gw_history_df = pd.DataFrame.from_records(data[\"current\"])\n",
    "    gw_history_df.to_csv(os.path.join(outfile_base, 'gws.csv'), index=False)\n",
    "\n",
    "def parse_entry_leagues(data, outfile_base):\n",
    "    classic_leagues_df = pd.DataFrame.from_records(data[\"leagues\"][\"classic\"])\n",
    "    classic_leagues_df.to_csv(os.path.join(outfile_base, 'classic_leagues.csv'), index=False)\n",
    "    try:\n",
    "        cup_leagues_df = pd.DataFrame.from_records(data[\"leagues\"][\"cup\"][\"matches\"])\n",
    "        cup_leagues_df.to_csv(os.path.join(outfile_base, 'cup_leagues.csv'), index=False)\n",
    "    except KeyError:\n",
    "        print(\"No cups yet\")\n",
    "    h2h_leagues_df = pd.DataFrame.from_records(data[\"leagues\"][\"h2h\"])\n",
    "    h2h_leagues_df.to_csv(os.path.join(outfile_base, 'h2h_leagues.csv'), index=False)\n",
    "\n",
    "def parse_transfer_history(data, outfile_base):\n",
    "    wildcards_df = pd.DataFrame.from_records(data)\n",
    "    wildcards_df.to_csv(os.path.join(outfile_base, 'transfers.csv'), index=False)\n",
    "\n",
    "def parse_fixtures(data, outfile_base):\n",
    "    fixtures_df = pd.DataFrame.from_records(data)\n",
    "    fixtures_df.to_csv(os.path.join(outfile_base, 'fixtures.csv'), index=False)\n",
    "\n",
    "def parse_team_data(data, outfile_base):\n",
    "    teams_df = pd.DataFrame.from_records(data)\n",
    "    teams_df.to_csv(os.path.join(outfile_base, 'teams.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaners\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import os\n",
    "\n",
    "def clean_players(filename, base_filename):\n",
    "    \"\"\" Creates a file with only important data columns for each player\n",
    "\n",
    "    Args:\n",
    "        filename (str): Name of the file that contains the full data for each player\n",
    "    \"\"\"\n",
    "    headers = ['first_name', 'second_name', 'goals_scored', 'assists', 'total_points', 'minutes', 'goals_conceded', 'creativity', 'influence', 'threat', 'bonus', 'bps', 'ict_index', 'clean_sheets', 'red_cards', 'yellow_cards', 'selected_by_percent', 'now_cost', 'element_type']\n",
    "    fin = open(filename, 'r+', encoding='utf-8')\n",
    "    outname = base_filename + 'cleaned_players.csv'\n",
    "    os.makedirs(os.path.dirname(outname), exist_ok=True)\n",
    "    fout = open(outname, 'w+', encoding='utf-8', newline='')\n",
    "    reader = csv.DictReader(fin)\n",
    "    writer = csv.DictWriter(fout, headers, extrasaction='ignore')\n",
    "    writer.writeheader()\n",
    "    for line in reader:\n",
    "        if line['element_type'] == '1':\n",
    "            line['element_type'] = 'GK'\n",
    "        elif line['element_type'] == '2':\n",
    "            line['element_type'] = 'DEF'\n",
    "        elif line['element_type'] == '3':\n",
    "            line['element_type'] = 'MID'\n",
    "        elif line['element_type'] == '4':\n",
    "            line['element_type'] = 'FWD'\n",
    "        else:\n",
    "            print(\"Oh boy\")\n",
    "        writer.writerow(line)\n",
    "\n",
    "def id_players(players_filename, base_filename):\n",
    "    \"\"\" Creates a file that contains the name to id mappings for each player\n",
    "\n",
    "    Args:\n",
    "        players_filename (str): Name of the file that contains the full data for each player\n",
    "    \"\"\"\n",
    "    headers = ['first_name', 'second_name', 'id']\n",
    "    fin = open(players_filename, 'r+', encoding='utf-8')\n",
    "    outname = base_filename + 'player_idlist.csv'\n",
    "    os.makedirs(os.path.dirname(outname), exist_ok=True)\n",
    "    fout = open(outname, 'w+', encoding='utf-8', newline='')\n",
    "    reader = csv.DictReader(fin)\n",
    "    writer = csv.DictWriter(fout, headers, extrasaction='ignore')\n",
    "    writer.writeheader()\n",
    "    for line in reader:\n",
    "        writer.writerow(line)\n",
    "\n",
    "def get_player_ids(base_filename):\n",
    "    \"\"\" Gets the list of all player ids and player names\n",
    "    \"\"\"\n",
    "    filename = base_filename + 'player_idlist.csv'\n",
    "    fin = open(filename, 'r+', encoding='utf-8')\n",
    "    reader = csv.DictReader(fin)\n",
    "    player_ids = {}\n",
    "    for line in reader:\n",
    "        k = int(line['id'])\n",
    "        v = line['first_name'] + '_' + line['second_name']\n",
    "        player_ids[k] = v\n",
    "    return player_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "def get_data():\n",
    "    \"\"\" Retrieve the fpl player data from the hard-coded url\n",
    "    \"\"\"\n",
    "    response = requests.get(\"https://fantasy.premierleague.com/api/bootstrap-static/\")\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\"Response was code \" + str(response.status_code))\n",
    "    responseStr = response.text\n",
    "    data = json.loads(responseStr)\n",
    "    return data\n",
    "\n",
    "def get_individual_player_data(player_id):\n",
    "    \"\"\" Retrieve the player-specific detailed data\n",
    "\n",
    "    Args:\n",
    "        player_id (int): ID of the player whose data is to be retrieved\n",
    "    \"\"\"\n",
    "    base_url = \"https://fantasy.premierleague.com/api/element-summary/\"\n",
    "    full_url = base_url + str(player_id) + \"/\"\n",
    "    response = ''\n",
    "    while response == '':\n",
    "        try:\n",
    "            response = requests.get(full_url)\n",
    "        except:\n",
    "            time.sleep(5)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\"Response was code \" + str(response.status_code))\n",
    "    data = json.loads(response.text)\n",
    "    return data\n",
    "\n",
    "def get_entry_data(entry_id):\n",
    "    \"\"\" Retrieve the summary/history data for a specific entry/team\n",
    "\n",
    "    Args:\n",
    "        entry_id (int) : ID of the team whose data is to be retrieved\n",
    "    \"\"\"\n",
    "    base_url = \"https://fantasy.premierleague.com/api/entry/\"\n",
    "    full_url = base_url + str(entry_id) + \"/history/\"\n",
    "    response = ''\n",
    "    while response == '':\n",
    "        try:\n",
    "            response = requests.get(full_url)\n",
    "        except:\n",
    "            time.sleep(5)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\"Response was code \" + str(response.status_code))\n",
    "    data = json.loads(response.text)\n",
    "    return data\n",
    "\n",
    "def get_entry_personal_data(entry_id):\n",
    "    \"\"\" Retrieve the summary/history data for a specific entry/team\n",
    "\n",
    "    Args:\n",
    "        entry_id (int) : ID of the team whose data is to be retrieved\n",
    "    \"\"\"\n",
    "    base_url = \"https://fantasy.premierleague.com/api/entry/\"\n",
    "    full_url = base_url + str(entry_id) + \"/\"\n",
    "    response = ''\n",
    "    while response == '':\n",
    "        try:\n",
    "            response = requests.get(full_url)\n",
    "        except:\n",
    "            time.sleep(5)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\"Response was code \" + str(response.status_code))\n",
    "    data = json.loads(response.text)\n",
    "    return data\n",
    "\n",
    "def get_entry_gws_data(entry_id,num_gws,start_gw=1):\n",
    "    \"\"\" Retrieve the gw-by-gw data for a specific entry/team\n",
    "\n",
    "    Args:\n",
    "        entry_id (int) : ID of the team whose data is to be retrieved\n",
    "    \"\"\"\n",
    "    base_url = \"https://fantasy.premierleague.com/api/entry/\"\n",
    "    gw_data = []\n",
    "    for i in range(start_gw, num_gws+1):\n",
    "        full_url = base_url + str(entry_id) + \"/event/\" + str(i) + \"/picks/\"\n",
    "        response = ''\n",
    "        while response == '':\n",
    "            try:\n",
    "                response = requests.get(full_url)\n",
    "            except:\n",
    "                time.sleep(5)\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(\"Response was code \" + str(response.status_code))\n",
    "        data = json.loads(response.text)\n",
    "        gw_data += [data]\n",
    "    return gw_data\n",
    "\n",
    "def get_entry_transfers_data(entry_id):\n",
    "    \"\"\" Retrieve the transfer data for a specific entry/team\n",
    "\n",
    "    Args:\n",
    "        entry_id (int) : ID of the team whose data is to be retrieved\n",
    "    \"\"\"\n",
    "    base_url = \"https://fantasy.premierleague.com/api/entry/\"\n",
    "    full_url = base_url + str(entry_id) + \"/transfers/\"\n",
    "    response = ''\n",
    "    while response == '':\n",
    "        try:\n",
    "            response = requests.get(full_url)\n",
    "        except:\n",
    "            time.sleep(5)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\"Response was code \" + str(response.status_code))\n",
    "    data = json.loads(response.text)\n",
    "    return data\n",
    "\n",
    "def get_fixtures_data():\n",
    "    \"\"\" Retrieve the fixtures data for the season\n",
    "    \"\"\"\n",
    "    url = \"https://fantasy.premierleague.com/api/fixtures/\"\n",
    "    response = ''\n",
    "    while response == '':\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "        except:\n",
    "            time.sleep(5)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\"Response was code \" + str(response.status_code))\n",
    "    data = json.loads(response.text)\n",
    "    return data\n",
    "\n",
    "def main():\n",
    "    data = get_data()\n",
    "    with open('raw.json', 'w') as outf:\n",
    "        json.dump(data, outf)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "def get_teams(directory):\n",
    "teams = {}\n",
    "fin = open(directory + \"/teams.csv\", 'r')\n",
    "reader = csv.DictReader(fin)\n",
    "for row in reader:\n",
    "teams[int(row['id'])] = row['name']\n",
    "return teams\n",
    "\n",
    "def get_fixtures(directory):\n",
    "fixtures_home = {}\n",
    "fixtures_away = {}\n",
    "fin = open(directory + \"/fixtures.csv\", 'r')\n",
    "reader = csv.DictReader(fin)\n",
    "for row in reader:\n",
    "fixtures_home[int(row['id'])] = int(row['team_h'])\n",
    "fixtures_away[int(row['id'])] = int(row['team_a'])\n",
    "return fixtures_home, fixtures_away\n",
    "\n",
    "def get_positions(directory):\n",
    "positions = {}\n",
    "names = {}\n",
    "pos_dict = {'1': \"GK\", '2': \"DEF\", '3': \"MID\", '4': \"FWD\"}\n",
    "fin = open(directory + \"/players_raw.csv\", 'r',encoding=\"utf-8\")\n",
    "reader = csv.DictReader(fin)\n",
    "for row in reader:\n",
    "positions[int(row['id'])] = pos_dict[row['element_type']]\n",
    "names[int(row['id'])] = row['first_name'] + ' ' + row['second_name']\n",
    "return names, positions\n",
    "\n",
    "def get_expected_points(gw, directory):\n",
    "xPoints = {}\n",
    "try:\n",
    "fin = open(os.path.join(directory, 'xP' + str(gw) + '.csv'), 'r')\n",
    "reader = csv.DictReader(fin)\n",
    "for row in reader:\n",
    "xPoints[int(row['id'])] = row['xP']\n",
    "except:\n",
    "return xPoints  \n",
    " return xPoints\n",
    "\n",
    "def merge_gw(gw, gw_directory):\n",
    "merged_gw_filename = \"merged_gw.csv\"\n",
    "gw_filename = \"gw\" + str(gw) + \".csv\"\n",
    "gw_path = os.path.join(gw_directory, gw_filename)\n",
    "fin = open(gw_path, 'r', encoding=\"utf-8\")\n",
    "reader = csv.DictReader(fin)\n",
    "fieldnames = reader.fieldnames\n",
    "fieldnames += [\"GW\"]\n",
    "rows = []\n",
    "for row in reader:\n",
    "row[\"GW\"] = gw\n",
    "rows += [row]\n",
    "out_path = os.path.join(gw_directory, merged_gw_filename)\n",
    "fout = open(out_path,'a', encoding=\"utf-8\")\n",
    "writer = csv.DictWriter(fout, fieldnames=fieldnames, lineterminator='\\n')\n",
    "print(gw)\n",
    "if gw == 1:\n",
    "writer.writeheader()\n",
    "for row in rows:\n",
    "writer.writerow(row)\n",
    "\n",
    "def collect*gw(gw, directory_name, output_dir, root_directory_name=\"data/2024-25\"):\n",
    "rows = []\n",
    "fieldnames = []\n",
    "fixtures_home, fixtures_away = get_fixtures(root_directory_name)\n",
    "teams = get_teams(root_directory_name)\n",
    "names, positions = get_positions(root_directory_name)\n",
    "xPoints = get_expected_points(gw, output_dir)\n",
    "for root, dirs, files in os.walk(u\"./\" + directory_name):\n",
    "for fname in files:\n",
    "if fname == 'gw.csv':\n",
    "fpath = os.path.join(root, fname)\n",
    "fin = open(fpath, 'r')\n",
    "reader = csv.DictReader(fin)\n",
    "fieldnames = reader.fieldnames\n",
    "for row in reader:\n",
    "if int(row['round']) == gw:\n",
    "id = int(os.path.basename(root).split('*')[-1])\n",
    "name = names[id]\n",
    "position = positions[id]\n",
    "fixture = int(row['fixture'])\n",
    "if row['was_home'] == True or row['was_home'] == \"True\":\n",
    "row['team'] = teams[fixtures_home[fixture]]\n",
    "else:\n",
    "row['team'] = teams[fixtures_away[fixture]]\n",
    "row['name'] = name\n",
    "row['position'] = position\n",
    "if id in xPoints:\n",
    "row['xP'] = xPoints[id]\n",
    "else:\n",
    "row['xP'] = 0.0\n",
    "rows += [row]\n",
    "\n",
    "    fieldnames = ['name', 'position', 'team', 'xP'] + fieldnames\n",
    "    outf = open(os.path.join(output_dir, \"gw\" + str(gw) + \".csv\"), 'w', encoding=\"utf-8\")\n",
    "    writer = csv.DictWriter(outf, fieldnames=fieldnames, lineterminator='\\n')\n",
    "    writer.writeheader()\n",
    "    for row in rows:\n",
    "        writer.writerow(row)\n",
    "\n",
    "def collect_all_gws(directory_name, output_dir, root_dir):\n",
    "for i in range(1,17):\n",
    "collect_gw(i, directory_name, output_dir, root_dir)\n",
    "\n",
    "def merge_all_gws(num_gws, gw_directory):\n",
    "for i in range(1, num_gws):\n",
    "merge_gw(i, gw_directory)\n",
    "\n",
    "def main():\n",
    "#collect_all_gws(sys.argv[1], sys.argv[2], sys.argv[3])\n",
    "merge_all_gws(int(sys.argv[1]), sys.argv[2])\n",
    "#collect_gw(26, sys.argv[1], sys.argv[2])\n",
    "\n",
    "if **name** == '**main**':\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import codecs\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def get_data(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\"Response was code \" + str(response.status_code))\n",
    "    html = response.text\n",
    "    parsed_html = BeautifulSoup(html, 'html.parser')\n",
    "    scripts = parsed_html.findAll('script')\n",
    "    filtered_scripts = []\n",
    "    for script in scripts:\n",
    "        if len(script.contents) > 0:\n",
    "            filtered_scripts += [script]\n",
    "    return scripts\n",
    "\n",
    "def get_epl_data():\n",
    "    scripts = get_data(\"https://understat.com/league/EPL/2024\")\n",
    "    teamData = {}\n",
    "    playerData = {}\n",
    "    for script in scripts:\n",
    "        for c in script.contents:\n",
    "            split_data = c.split('=')\n",
    "            data = split_data[0].strip()\n",
    "            if data == 'var teamsData':\n",
    "                content = re.findall(r'JSON\\.parse\\(\\'(.*)\\'\\)',split_data[1])\n",
    "                decoded_content = codecs.escape_decode(content[0], \"hex\")[0].decode('utf-8')\n",
    "                teamData = json.loads(decoded_content)\n",
    "            elif data == 'var playersData':\n",
    "                content = re.findall(r'JSON\\.parse\\(\\'(.*)\\'\\)',split_data[1])\n",
    "                decoded_content = codecs.escape_decode(content[0], \"hex\")[0].decode('utf-8')\n",
    "                playerData = json.loads(decoded_content)\n",
    "    return teamData, playerData\n",
    "\n",
    "def get_player_data(id):\n",
    "    scripts = get_data(\"https://understat.com/player/\" + str(id))\n",
    "    groupsData = {}\n",
    "    matchesData = {}\n",
    "    shotsData = {}\n",
    "    for script in scripts:\n",
    "        for c in script.contents:\n",
    "            split_data = c.split('=')\n",
    "            data = split_data[0].strip()\n",
    "            if data == 'var matchesData':\n",
    "                content = re.findall(r'JSON\\.parse\\(\\'(.*)\\'\\)',split_data[1])\n",
    "                decoded_content = codecs.escape_decode(content[0], \"hex\")[0].decode('utf-8')\n",
    "                matchesData = json.loads(decoded_content)\n",
    "            elif data == 'var shotsData':\n",
    "                content = re.findall(r'JSON\\.parse\\(\\'(.*)\\'\\)',split_data[1])\n",
    "                decoded_content = codecs.escape_decode(content[0], \"hex\")[0].decode('utf-8')\n",
    "                shotsData = json.loads(decoded_content)\n",
    "            elif data == 'var groupsData':\n",
    "                content = re.findall(r'JSON\\.parse\\(\\'(.*)\\'\\)',split_data[1])\n",
    "                decoded_content = codecs.escape_decode(content[0], \"hex\")[0].decode('utf-8')\n",
    "                groupsData = json.loads(decoded_content)\n",
    "    return matchesData, shotsData, groupsData\n",
    "\n",
    "def parse_epl_data(outfile_base):\n",
    "    teamData,playerData = get_epl_data()\n",
    "    new_team_data = []\n",
    "    for t,v in teamData.items():\n",
    "        new_team_data += [v]\n",
    "    for data in new_team_data:\n",
    "        team_frame = pd.DataFrame.from_records(data[\"history\"])\n",
    "        team = data[\"title\"].replace(' ', '_')\n",
    "        team_frame.to_csv(os.path.join(outfile_base, 'understat_' + team + '.csv'), index=False)\n",
    "    player_frame = pd.DataFrame.from_records(playerData)\n",
    "    player_frame.to_csv(os.path.join(outfile_base, 'understat_player.csv'), index=False)\n",
    "    for d in playerData:\n",
    "        matches, shots, groups = get_player_data(int(d['id']))\n",
    "        indi_player_frame = pd.DataFrame.from_records(matches)\n",
    "        player_name = d['player_name']\n",
    "        player_name = player_name.replace(' ', '_')\n",
    "        indi_player_frame.to_csv(os.path.join(outfile_base, player_name + '_' + d['id'] + '.csv'), index=False)\n",
    "\n",
    "class PlayerID:\n",
    "    def __init__(self, us_id, fpl_id, us_name, fpl_name):\n",
    "        self.us_id = str(us_id)\n",
    "        self.fpl_id = str(fpl_id)\n",
    "        self.us_name = us_name\n",
    "        self.fpl_name = fpl_name\n",
    "\n",
    "\n",
    "def match_ids(understat_dir, data_dir):\n",
    "    with open(os.path.join(understat_dir, 'understat_player.csv')) as understat_file:\n",
    "        understat_inf = csv.DictReader(understat_file)\n",
    "        ustat_players = {}\n",
    "        for row in understat_inf:\n",
    "            ustat_players[row['player_name']] = row['id']\n",
    "\n",
    "    with open(os.path.join(data_dir, 'player_idlist.csv')) as fpl_file:\n",
    "        fpl_players = {}\n",
    "        fpl_inf = csv.DictReader(fpl_file)\n",
    "        for row in fpl_inf:\n",
    "            fpl_players[row['first_name'] + ' ' + row['second_name']] = row['id']\n",
    "    players = []\n",
    "    found = {}\n",
    "    for k, v in ustat_players.items():\n",
    "        if k in fpl_players:\n",
    "            player = PlayerID(v, fpl_players[k], k, k)\n",
    "            players += [player]\n",
    "            found[k] = True\n",
    "        else:\n",
    "            player = PlayerID(v, -1, k, \"\")\n",
    "            players += [player]\n",
    "\n",
    "    for k, v in fpl_players.items():\n",
    "        if k not in found:\n",
    "            player = PlayerID(-1, v, \"\", k)\n",
    "            players += [player]\n",
    "\n",
    "    with open(os.path.join(data_dir, 'id_dict.csv'), 'w+') as outf:\n",
    "        outf.write('Understat_ID, FPL_ID, Understat_Name, FPL_Name\\n')\n",
    "        for p in players:\n",
    "            outf.write(p.us_id + \",\" + p.fpl_id + \",\" + p.us_name + \",\" + p.fpl_name + \"\\n\")\n",
    "\n",
    "def main():\n",
    "    #parse_epl_data('data/2021-22/understat')\n",
    "    #md, sd, gd = get_player_data(318)\n",
    "    #match_frame = pd.DataFrame.from_records(md)\n",
    "    #match_frame.to_csv('auba.csv', index=False)\n",
    "    match_ids('data/2024-25/understat', 'data/2024-25')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FPL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
